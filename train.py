import os
import cv2
import numpy as np
import torch
from torch.utils.data import DataLoader, Dataset
import segmentation_models_pytorch as smp
import albumentations as A
from albumentations.pytorch import ToTensorV2

# 1. å‹æ¦¨æ€§èƒ½é…ç½®

TRAIN_DIR = './dataset/training'
VAL_DIR = './dataset/validation'
ENCODER = 'mobilenet_v2'
ENCODER_WEIGHTS = 'imagenet'
CLASSES = 1
ACTIVATION = 'sigmoid'
DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'

# âš¡ï¸ æ ¸å¿ƒæ”¹åŠ¨ 1: åˆ†è¾¨ç‡æå‡åˆ° 512
IMG_SIZE = 512
# âš¡ï¸ æ ¸å¿ƒæ”¹åŠ¨ 2: æ˜¾å­˜ä¸å¤Ÿå°±æ”¹å°è¿™ä¸ª (æ¯”å¦‚ 4)
BATCH_SIZE = 4
LR = 0.0003

# âš¡ï¸ ä¿®æ”¹ç‚¹ 1: è½®æ•°æ”¹ä¸º 200
EPOCHS = 200
TARGET_TYPE = 'cardiac'


# 2. å¢å¼ºç­–ç•¥ (ä¿æŒå¼ºåŠ›)

train_transform = A.Compose([
    A.Resize(IMG_SIZE, IMG_SIZE),
    A.HorizontalFlip(p=0.5),
    A.Rotate(limit=20, p=0.5),
    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.15, rotate_limit=0, p=0.5),
    A.GaussNoise(p=0.2),
    A.OpticalDistortion(distort_limit=0.05, p=0.2),
    A.OneOf([
        A.RandomBrightnessContrast(p=1),
        A.RandomGamma(p=1),
    ], p=0.3),
    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),
    ToTensorV2(),
])

val_transform = A.Compose([
    A.Resize(IMG_SIZE, IMG_SIZE),
    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),
    ToTensorV2(),
])


# ============================
# 3. æ•°æ®é›† (Dataset)
# ============================
class UltimateDataset(Dataset):
    def __init__(self, root_dir, transform=None):
        self.root_dir = root_dir
        self.transform = transform
        self.images_dir = os.path.join(root_dir, 'images')
        self.masks_dir = os.path.join(root_dir, 'annfiles_mask')
        self.ids = [f for f in os.listdir(self.images_dir) if f.endswith('.png')]

    def __getitem__(self, i):
        img_name = self.ids[i]
        img_path = os.path.join(self.images_dir, img_name)
        mask_name = img_name.replace(".png", f"-{TARGET_TYPE}.png")
        mask_path = os.path.join(self.masks_dir, mask_name)

        image = cv2.imread(img_path)
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        if not os.path.exists(mask_path):
            mask = np.zeros((image.shape[0], image.shape[1]), dtype=np.uint8)
        else:
            mask = cv2.imread(mask_path, 0)

        mask = mask.astype('float32')
        mask[mask < 127] = 0.0
        mask[mask >= 127] = 1.0

        if self.transform:
            augmented = self.transform(image=image, mask=mask)
            image = augmented['image']
            mask = augmented['mask']

        mask = mask.unsqueeze(0)
        return image, mask

    def __len__(self):
        return len(self.ids)


def calculate_iou(pred_mask, true_mask):
    pred_mask = (pred_mask > 0.5).float()
    intersection = (pred_mask * true_mask).sum()
    union = pred_mask.sum() + true_mask.sum() - intersection
    if union == 0: return 1.0
    return intersection / union



# 4. ä¸»ç¨‹åº

if __name__ == '__main__':
    train_ds = UltimateDataset(TRAIN_DIR, transform=train_transform)
    val_ds = UltimateDataset(VAL_DIR, transform=val_transform)

    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)
    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)

    print(f"ğŸ”¥ MobileNetV2 æé™æŒ‘æˆ˜å¼€å§‹ï¼åˆ†è¾¨ç‡: {IMG_SIZE}x{IMG_SIZE}, ç›®æ ‡: Min IoU > 0.87")

    model = smp.FPN(
        encoder_name=ENCODER,
        encoder_weights=ENCODER_WEIGHTS,
        classes=CLASSES,
        activation=ACTIVATION
    )
    model.to(DEVICE)

    loss_fn = smp.losses.JaccardLoss(smp.losses.BINARY_MODE, from_logits=False)
    optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-3)
    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=15, T_mult=2)

    best_iou = 0.0

    for epoch in range(EPOCHS):
        model.train()
        train_loss = 0
        for images, masks in train_loader:
            images, masks = images.to(DEVICE), masks.to(DEVICE)

            optimizer.zero_grad()
            outputs = model(images)
            loss = loss_fn(outputs, masks)
            loss.backward()
            optimizer.step()
            train_loss += loss.item()

        model.eval()

        # âš¡ï¸ ä¿®æ”¹ç‚¹ 2: æ”¹ä¸ºæ”¶é›†æ‰€æœ‰å•å¼ å›¾ç‰‡çš„ IoUï¼Œä»¥ä¾¿è®¡ç®— Min IoU
        val_ious = []
        with torch.no_grad():
            for images, masks in val_loader:
                images, masks = images.to(DEVICE), masks.to(DEVICE)
                outputs = model(images)

                # å¿…é¡»è®¡ç®— Batch ä¸­æ¯ä¸€å¼ å›¾çš„ IoUï¼Œè€Œä¸æ˜¯æ•´ä¸ª Batch çš„ IoU
                for i in range(images.size(0)):
                    single_pred = outputs[i:i + 1]
                    single_mask = masks[i:i + 1]
                    single_iou = calculate_iou(single_pred, single_mask).item()
                    val_ious.append(single_iou)

        scheduler.step()

        # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
        avg_val_iou = sum(val_ious) / len(val_ious)
        min_val_iou = min(val_ious)  # æ‰¾å‡ºè¿™ä¸€è½®çš„â€œæœ€çŸ­æ¿â€

        print(
            f"Epoch [{epoch + 1}/{EPOCHS}] Loss: {train_loss / len(train_loader):.4f} | Val IoU: {avg_val_iou:.4f} | Min IoU: {min_val_iou:.4f}")

        if avg_val_iou > best_iou:
            best_iou = avg_val_iou
            torch.save(model.state_dict(), 'best_mobile_v2_512.pth')
            print(f"    ğŸ† æ–°çºªå½•ï¼Avg IoU: {best_iou:.4f} (Min: {min_val_iou:.4f})")

    print(f"âœ… æŒ‘æˆ˜ç»“æŸã€‚æœ€é«˜ Avg IoU: {best_iou:.4f}")
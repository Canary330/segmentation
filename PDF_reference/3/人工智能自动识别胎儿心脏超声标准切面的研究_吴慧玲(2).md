分类号 R445.1

学校代码： 10392

学 号：6150103062

学科专业代码：105107

密

级：

硕士学位论文

人工智能自动识别胎儿心脏超声标准切面的研究

Artificial intelligence automatically identifies standard

sections of fetal heart ultrasound

学

所

位

在

类

学

型 ：

院 ：

临床医学硕士

第二临床医学院

吴慧玲

申 请 人 姓 名 ：

学 科 、 专 业 ：

影像医学与核医学

导

师：

何韶铮副教授

研 究 起 止 日 期 ： 2020 年 12 月至 2022 年 9 月

答 辩 委 员 会 主 席 ： 李拾林 教授

期 ： 2023 年 5 月 16 日

答

辩

日

二○二三年五月

目 录

前言.............................................................................................................5

材料与方法.................................................................................................8

1 一般资料..............................................................................................8

1.1 不同等级医师的分类标准............................................................8

1.2 图像收集方法................................................................................9

2 实验环境............................................................................................10

3 人工智能模型构建............................................................................11

3.1 基于传统手工特征的胎儿超声心脏标准五切面自动识别和分

类模型的构建 ...................................................................................11

3.2 基于深度学习的胎儿超声心脏标准五切面自动识别和分类模

型的构建 ...........................................................................................16

4 统计学处理........................................................................................24

结果...........................................................................................................25

1 基于传统手工特征模型的实验结果 ...............................................25

1.1 LH-BOW 对不同心脏标准切面的识别效果 .............................25

1.2 LH-BOW 与不同 AI 自动识别模型的心脏标准切面识别效果

对比 ...................................................................................................26

2 基于深度学习模型的实验结果 .......................................................27

2.1 U-Y-Net 模型对每个解剖结构的识别结果................................27

2.2 模型对比实验..............................................................................29

2.3 不同医师与 U-Y-Net 之间的对比实验......................................29

讨论...........................................................................................................31

结论...........................................................................................................35

参考文献...................................................................................................36

附录 英文缩略词表 ................................................................................41

综述 医学人工智能在产前超声方面的研究进展 ................................43

参考文献................................................................................................48

福建医科大学硕士学位论文

人工智能自动识别胎儿心脏超声标准切面的研究

摘要

目的：通过医学超声影像技术与人工智能技术结合，建立有效的模型用以识

别产前胎儿心脏超声标准切面的图像。

资料与方法：采集 18-24+6 孕周正常胎儿标准超声心尖四腔心、左室流出道、

右室流出道、三血管、三血管气管五个切面（1）每个切面 200 张用于模型建立、

50 张用于模型测试。提出一种传统手工特征识别模型（LH-BOW），实现对胎

儿心脏超声图像的自动识别和分类。应用准确率、阳性预测值、灵敏度、F1-分

数评价 LH-BOW 模型的性能。（2）纳入 2687 张图像数据用于模型建立、673

张图像数据用于模型测试、另纳入包含非标准切面共 482 张图像数据用于不同医

师与模型的临床检验。利用解剖结构定位标准切面，提出一种深度卷积神经网络

模型（U-Y-Net），用于识别不同标准切面的解剖结构。应用 Map 值、准确率、

阳性预测值、灵敏度、特异度、F1-分数评价 U-Y-Net 的性能，U-Y-Net 与不同医

师之间的临床检验采用 McNemar 检验。

结果：1.LH-BOW 模型在识别不同心脏标准切面的准确率达到 89.60%，平

均阳性预测值达到 89.71%，平均灵敏度达到 89.60%，平均 F1-分数达到 89.61%。

LH-BOW 比 LBP 模 型 、 HOG 模 型 、 SURF-BOW 词 袋 模 型 、 LBP-HOG 、

LBP++HOG+GLCM 模型、Sono-net32 模型的整体实验性能更佳（P<0.05)。

2.U-Y-Net 模型识别不同解剖结构的 Map 值达到 94.30%，平均阳性预测值达

到 94.60%，平均召回率达到 91.0%，平均 F1-分数达到 93.40%。U-Y-Net 的 Map、

阳 性 预 测 值 、 灵 敏 度 与 F1 分 数 均 高 于 Fast-RCNN&Mobilenetv2 、

Fast-RCNN&Res-Net50、RetinaNet&Res-Net50、SSD&Res-Net50、VGG-Net，其

中最好的 Fast-RCNN&Mobilenetv2 在 Map 上结果也仅能达到 81.2%。U-Y-Net

比 YOLOv5 的 Map 值提高 0.9%。U-Y-Net 切面识别上整体准确率、阳性预测值、

灵敏度均优于初级医师（P<0.05)，与中级医师相当。

结论：1.LH-BOW 在有限的样本量中能有效地识别分类胎儿心脏标准五切

面，具有初步筛查胎儿心脏五切面的潜力，可能帮助医师减少胎儿心脏产前筛查

工作的负荷。

1

福建医科大学硕士学位论文

2.U-Y-Net 能识别胎儿心脏的诸多重要结构，不仅具有辅助医生识别分类标

准切面的作用，还具有帮助医生筛查先天性心脏病的潜在价值。

关键词：胎儿心脏，超声心动图，人工智能

2

福建医科大学硕士学位论文

Artificial intelligence automatically identifies standard sections

of fetal heart ultrasound

ABSTRACT

Objectives:To identify the standard section of fetal cardiac ultrasound by an

effective model established through the combination of ultrasound image technology

and artificial intelligence technology.

Methods: Standard sections of four-chamber heart, left ventricular outflow tract,

right ventricular outflow tract, three-vessel and three-vessel trachea were collected

from 18-24+6 weeks of gestation. (1) 200 pieces of each section were used for model

establishment and 50 pieces of each section were used for model verification. A

traditional manual feature recognition model (LH-BOW) was proposed to realize

automatic recognition and classification of fetal heart ultrasound images.The

performance of LH-BOW was evaluated by accuracy, positive predictive value,

sensitivity and F1-score. (2) 2687 images were included for model establishment, 673

images were used for model validation, and 482 images including non-standard

sections were included for clinical examination between different physicians and

models. A deep convolution neural network model (U-Y-Net) was proposed to

identify the anatomical structures of different standard sections by using anatomical

structures to locate standard sections. Map value, accuracy, positive predictive value,

sensitivity, specificity, and F1 score were used to evaluate the performance of

U-Y-Net. The clinical test between U-Y-Net and different physicians was performed

by McNemar test.

Results: 1. LH-BOW achieved an accuracy of 89.60%, average accuracy of

89.71%, average sensitivity of 89.60%, and average F1 coefficient of 89.61%.

LH-BOW performed better than the LBP model, HOG model, SURF-BOW word bag

model, LBP-HOG, LBP + + HOG + GLCM model, and Sono-net32 model (P <0.05).

2.The Map value of U-Y-Net identifying different anatomical structures reached

94.30%, the average accuracy rate reached 94.60%, the average recall rate reached

91.0%, and the average F1 coefficient reached 93.40%. U-Y-Net's Map, positive

3

福建医科大学硕士学位论文

predictive value, sensitivity and F1 score are higher than Fast-RCN&Mobilenetv2,

Fast-RCN&Res-Net50, RetinaNet&Res-Net50, SSD&Res-Net50, VGG-Net. Among

them, the best Fast-RCN&Mobilenetv2 can only reach 81.2% on the Map. The Map

value of U-Y-Net is 0.9% higher than that of YOLOv5. The overall accuracy, positive

predictive value and sensitivity of U-Y-Net section recognition were better than those

of primary physicians (P<0.05), and are equivalent to those of intermediate

physicians.

Conclusions: 1. LH-BOW can effectively identify and classify five standard

sections of fetal heart in a limited sample size, which may help doctors reduce the

workload of prenatal screening of fetal heart.

2.U-Y-Net can identify many important structures of fetal heart. It not only helps

doctors to identify and classify the standard sections，but also has the potential value

in screening of fetal congenital heart diseases.

Key words: Fetal heart, Ultrasound Echocardiography, Artificial Intelligence

4

福建医科大学硕士学位论文

前言

先天性心脏病(Congenital Heart Disease，CHD)范围包括了从不需要医疗或

手术干预的轻微心脏结构缺陷到复杂的结构异常[1] 。CHD 是目前最常见的出生

缺陷之一,影响着全球 1%的婴儿[2]。CHD 在我国的发病率为 0.5%～9%，每年我

国新增的 CHD 的新生儿接近 9-15 万[3]。随着我国二胎政策的开放以及经济与科

学的发展，全社会对提高胎儿心脏畸形的检出率，降低新生儿心脏缺陷发病率的

需求越来越强烈，产前诊断出 CHD，能够在一定程度上改善胎儿的预后。目前

首选产前诊断 CHD 的方法是应用超声技术筛查[4]，即通过产前心脏超声动态观

察胎儿心脏的发育情况诊断 CHD，这有利于临床医师在后续治疗中采取合理措

施，从而避免或减轻血液动力学损害的发生[5-6]。

现如今推荐最佳心脏筛查时间为妊娠中期[7]，在妊娠中期使用二维超声可直

观地评估胎儿心脏及其主要结构的发育和功能[8]。常用于筛查并判断心脏结构的

切面有心尖四腔心切面（Four Chamber View，4CH）、右室流出道切面（Right

Ventricular Outflow Tract，RVOT）、左室流出道切面（Left Ventricular Outflow

Tract，LVOT)、三血管气管切面(Three Vessel Trachea View，3VT)、三血管导管

切面(Three Vessel View，3VV)五个切面[9]，每个切面均有需要关注的心脏解剖结

构与重要的毗邻结构。超声医师需要通过识别这些切面并判断分析心脏各房室位

置、大小、与相应动脉连接关系、心脏大血管的对应位置与大小等进行筛查与诊

断。

CHD 的检出率在实际的超声工作中受到诸多客观因素的影响，例如不同超

声设备的参数差异、胎方位、羊水量以及孕妇的脂肪层厚度等，均可影响图像的

成像质量，导致检出率下降。即便随着产前超声诊断的普及和超声医师的标准化

培训的推广，产前超声医师的专业技能已经有了很大的提高[10]，图像识别对于产

前超声医师的负荷仍然很大，对超声医师的能力有着极高的要求。与此同时，日

常超声工作中也存在着各种影响超声医生图像识别的主观因素，譬如经验不同、

认知水平差异和工作疲劳等，都可能影响后续的诊断[11]。在这情况下，找到一种

既能够减轻医师的工作负荷，又能提高医师识别准确率的方法是现阶段迫切需要

解决的事情。

5

福建医科大学硕士学位论文

近年来，人工智能（Artificial Intelligence，AI）快速发展，已渐渐改变人们

的生活，探讨人工智能在医学影像学的应用逐渐成为热点。事实上，早在 2008

年，Liu XP 等[12]便利用 AI 技术自动搜索三维超声的最佳心脏横切面，并证明了

AI 搜索优于手工搜索。Yi X 等[13]通过调整相关参数，使 AI 识别电子计算机断层

扫描（Computed Tomography，CT）图像的效能提高。2015 年霍宇欢等[14]设计了

一种经食管超声心动图标准切面导航可视化系统，实现了通过食管探头的实时导

航功能,做到立体呈现经食管超声心动图的采集技术操作过程，有效帮助临床医

生增强对心脏的空间立体结构的认识、掌握超声心动图采集技术、准确地分析诊

断病例。2018 年 Mehdi A 等[15]使用深度卷积生成对抗网络合成胸部 X 线图像，

使用两种对抗网络生成正常和异常胸部 X 线图像，并从分类和放射科医生分级

方面评估结果图像质量。同年 Zhang Q 等[16]使用对抗生成神经网络进行数据增

强，以提高组织图像的准确性。AI 在产前超声检查胎儿颜面及颅脑方面也有所

应用，Chen X[17]利用深度学习（Deep Learning，DL）在二维超声图像中完成 AI

自动测量胎儿侧脑室宽度，Xie HN 等[18]通过对算法进行了胎儿颅骨图像分割、

图像分类和病灶定位三方面的训练，验证了 DL 可以训练对正常和异常图像进行

分割和分类，并可提供病灶定位的图像。Lei B 等[19]利用 Fisher 矢量自动识别胎

儿颜面结构并获得了较好的效果，说明了 AI 可以高效的识别胎儿颜面结构并有

望应用于胎儿其他器官。但在胎儿心脏方面的应用，AI 尚在起步之际。有研究[20]

通过收集正常对照、室间隔缺损(Ventricular Septal Defect，VSD)患者和房间隔缺

损(Atrial Septal Defect，ASD)患者的超声心动图视频记录，利用 DL 建立研究模

型并做到了准确率 90%以上的诊断效能。Lu X 等[21]对四腔心切面视图数据集上

进行的大量实验,表明 DW-Net 对四腔心切面分割效果良好,实现了 AI 和医学之

间的交叉应用，这些均说明了 AI 在心脏方面具有可行性及良好的应用前景。

因此，本研究旨在利用 AI 与超声技术相结合，寻求更便捷、更高效的方式

来分类识别胎儿心脏标准切面以期帮助医师更好的认识心脏切面并学习心脏重

要的解剖结构，从而降低不同医师、不同仪器、不同地区等多种因素导致的胎儿

心脏超声标准切面识别获取准确率的差异。通过 AI 减少人力物力在超声日常培

训的投入、降低超声医师有限资源的消耗、促进基层医生的长期专业培训。有助

于超声医师在日常工作中的超声图像质量控制、提高我国 CHD 的初级诊断率、

6

福建医科大学硕士学位论文

为 CHD 的早期诊断奠定基础。

7

福建医科大学硕士学位论文

材料与方法

1 一般资料

本研究研究对象为 18 至 24+6 孕周的正常胎儿心脏超声标准切面图像，共 406

例胎儿。图像包括 4CH、RVOT、LVOT、3VT、3VV 五个标准切面以及不完全

符合上述标准切面特点的非标准切面。图像根据研究需要分为训练集图像、测试

集图像以及外部验证集图像。其中训练集和测试集的比例采用 8:2 的比例适配模

型建立。测试集图像是为评估 AI 模型对不同来源的正常胎儿心脏超声标准切面

图像的识别性能，外部验证集图像是用于评价 AI 模型与不同等级医师识别分类

正常胎儿心脏超声标准切面图像能力。本研究经福建医科大学附属第二医院伦理

委员会审查批准通过，伦理编号：[2022]福医附二伦理审字（92）号。图像来源

于福建医科大学附属第二医院超声科，图像采集机器为 GE E10、迈瑞 R8、迈瑞

I9S。

本研究分为两部分：

①第一部分为分析超声图像的成像优缺点，采用针对性的传统手工特征提取

方法，提出 LH-BOW 模型用于识别胎儿心脏超声标准切面，并验证模型的性能。

经专家超声医师筛选纳入，其中用于模型训练的胎儿心脏超声标准切面图像

1000 张，测试模型性能的胎儿心脏超声标准切面图像 250 张。

②第二部分根据国际妇产科超声学会（International Society of Ultrasound in

Obstetrics and Gynecology，ISUOG）[9]与中国胎儿心脏超声检查指南[22]等相应超

声指南所定义的胎儿心脏超声标准切面具有的解剖结构，经过商讨、建立一种新

型计算机图像标注方案。在此基础上，提出了一种用于识别胎儿心脏超声标准切

面解剖结构的深度学习 U-Y-Net 模型，通过高性能识别解剖结构定位不同胎儿心

脏标准切面。其中纳入实验中的正常胎儿心脏超声标准切面图像共 3360 张，分

为训练集 2687 张、测试集 673 张，另采集包含非标准切面的心脏超声五切面 482

张作为外部验证集。

1.1 不同等级医师的分类标准

通过是否完成超声住院医师规范化培训（Standardized Training for Residents，

STFR），是否完成 3 年及以上产科超声专科培训（Specialized Training in Obstetric

8

福建医科大学硕士学位论文

Ultrasound，STOUS）将不同经验的超声检查医师分为初级医师（Junior Physician，

JP）、中级医师（Intermediate Physician，IP）（表 1），专家级医师定义为具有

STOUS 师资并长期从事(至少 10 年）产前超声检查及诊断的超声医师。

表 1 不同等级医师的定义标准

Table1 Definition criteria for different levels of physicians

STFR

STOUS

STOUS 师资

JP

IP

+

+

+

-

+

+

专家

+

1.2 图像收集方法

标准切面采集标准的制定：胎儿心脏超声标准切面采集标准按照 ISUOG 指

南与中国胎儿心脏超声检查指南所定义的标准切面图像的采集标准（表 2）。由

福建医科大学附属第二医院超声科的主治及以上医师根据表 2 进行采集，经三位

具有产科超声专科培训资质、长期从事(至少 10 年）产前超声检查及诊断的专家

进行判别，三位专家判断一致的胎儿心脏标准切面图像作为标准切面，并作为

LH-BOW 及 U-Y-Net 模型识别能力判断的金标准，三位专家皆判断不是标准切

面的图像作为非标准胎儿心脏切面图，纳入第二部分的外部验证集。5 个标准切

面图如图 1 所示。

表 2 标准切面显示内容及标注结构

Table 2 Display content and annotation structure of the standard section

标准切面

显示内容

标注结构

4CH

二、三尖瓣附着点及房间隔和室间隔（十

字交叉），左右心腔大小大致相同

右心房、左心房、左心室、主动脉

与肺动脉相连的右心室、升主动脉及上腔

静脉，形成三血管并排图像

心房心室大致对称的 4CH

LVOT

RVOT

右心房、左心房、左心室、主动脉

右心室、升主动脉、上腔静脉

3VV

主肺动脉在分叉处发出左右肺动脉，形成

“Y”字形结构，和（或）显示主动脉、上

腔静脉、降主动脉

分叉的肺动脉，主动脉

9

福建医科大学硕士学位论文

3VT

主动脉及主肺动脉三者形成“V”字形结构， 主动脉、主肺动脉、上腔静脉以及

显示上腔静脉和气管

气管

图 1 胎儿心脏标准切面的超声图像：（A）右室流出道切面;（B）左室流出道切面;（C）三

血管切面;（D）四腔心切面;（E）三血管气管切面

Figure 1 Ultrasound images of the standard sections of the fetal heart :(A) （right ventricular

outflow tract; (B) left ventricular outflow tract; (C) three-vessel view; (D) four-chamber view； (E)

three-vessel trachea view

图像纳入标准：（1）超声孕龄与实际孕龄大致相符；（2）图像清晰，目标

结构位于图像正中占据整个图像 1/2 以上，背景纯净无伪像；（3）图像无测量

点、线以及彩色多普勒血流信号；(4)产后证实胎儿无心脏畸形及其他结构畸形。

图像排除标准：（1）由于孕妇肥胖、图像抖动等因素导致心脏结构显示欠

满意；（2）图像心脏结构不完整；（3）超声检查或产后证实胎儿异常。

2 实验环境

计算机配置：中央处理器采用 Intel（R）Core（TM）i7-10700K，图形处理

器采用的是 NVIDIA GeForce GTX-1080Ti.显存 3G，内存 512G，计算机操作系

统为 64 位 Windows10，编程软件为 MATLABR2018b，Pycharm，图像标注软件

为 LabelImg。

10

福建医科大学硕士学位论文

3 人工智能模型构建

3.1 基于传统手工特征的胎儿超声心脏标准五切面自动识别和分

类模型的构建

第一部分提出一种传统手工特征提取方法，使用局部二值模式（Local Binary

Pattern，LBP）[23]和方向梯度直方图（Histogram of Oriented Gradient，HOG）[24]

进行纹理特征提取；采用具有加速稳定特征（Speeded up Robust Features，SURF）

[25]的视觉词袋模型（Bag of Words，BOW）[26]形成词袋特征，经过特征融合和高

维特征降维后，最后利用支持向量机（Support Vector Machines，SVM）对纹理

特征和视觉词袋特征进行学习建立模型（LH-BOW），实现对胎儿心脏超声图像

的自动识别和分类[27]（图 2）。此外，后期增加了模型对比实验，将第一部分所

建立的融合模型与单个模型、现阶段已成功应用于胎儿心脏超声标准切面的深度

学习模型进行比较。

图 2 LH-BOW 模型的构建过程：对原始图像进行预处理后将图像分为训练集和测试集两部分，

通过训练集建立模型后利用测试集进行模型测试

Figure 2 Construction process of the LH-BOW model :After pre-processing the original images,

the images are divided into two parts: training set and test set. After building the model through

the training set, the model test is conducted using the validation set

3.1.1 图像预处理

由于从超声仪器所采集的原始胎儿心脏图像包含了许多冗余信息（测量、病

11

福建医科大学硕士学位论文

人信息、时间及非心脏部分），所以在这种情况下要对原始图像采取感兴趣区域

分割提取即预先从图像中分割出待研究的区域，继而进行特征计算[28]。同时，不

同类型的图像像素点对比度越高，检测模型的效果越优异。在很多情况下，不同

切面的血管、心房心室相似度很高，在不同切面的对比度相对较低，所以输入到

AI 模型之前需要提高其对比度。本研究先将图像裁剪成易于AI 模型识别分类的

256*256 图像尺寸（图2），继而采取各向异性滤波器克服原始图像存在的斑点

噪声、对比度低等问题[29]。

3.1.2 纹理特征提取

(1)LBP

原始的LBP 算子定义为在某个中心像素和其周围矩阵形成的3*3 邻域内，

以中心像素为阈值，相邻的八个像素点的灰度值与中心像素的灰度值作比较，形

成二值量化，大于中心像素的灰度值的相邻点则标记为1，小于中心像素的灰度

值的相邻点则标记为0，从而产生一个二进制编码，得到该窗口中心像素点的

LBP 值。中心像素点的LBP 值反应该中心像素的周围区域的纹理信息。

局部二值模式的具体计算公式如下：

i7

i

LBP

s(g  g )2

(1)

(2)

x ,y

p

c

c

c

i0

1， (g  g )≥0

p

c

s(g  g )=

p

c

0， (g  g )＜0

p c

gc 为中心像素点的灰度值，P 代表中心像素点 ,Y 周围邻域的像素点，g

XC

C

p

表示第P 个邻域像素点的灰度值。不同的中心像素及邻域均可得到不同LBP 值。

(2)HOG

HOG 作为目前计算机视觉领域常用纹理特征的提取方法之一[30],在目标识

别、目标跟踪领域中的应用效果显著。HOG 是提取图像上的方向特征，以运算

梯度的形式作为提取手段，主要是提取图像的梯度方向和梯度幅度。即通计算统

计图片中某一区域每个算子的不同方向梯度直方图，以得到的直方图作为特征代

表该区域。

对于每个中心像素，梯度方向直方图的思想是首先利用梯度算子[-1 0 1]和

[-1 0 1]T 与图像卷积，得到任意像素点的梯度幅度和梯度方向。

12

福建医科大学硕士学位论文

梯度方向矩阵的具体计算公式如下：

I  F(x 1, y)  F(x 1, y)

x

(3)

(4)

I  F(x, y 1)  F(x, y 1)

y

m(x, y)  I

2

x

I

2

y

I

y

(x, y)  tan1 [0,360

。

)or [0,180

。

)

(5)

I

x

其中 I 和 I 分别是图像的像素点(x, y)处的水平和垂直梯度值，m(x, y) 为像

x

y

素点(x, y) 的梯度的模长大小，(x, y) 为像素点(x, y)的方向。

在纹理特征提取阶段，将目标图像按照细胞单元 Cell-size 划分，将 LBP 特

征与 HOG 特征重塑为许多相邻的细胞阵列，针对每个 Cell-size 计算二进制模式、

获取梯度方向直方图，每个 Cell-size 的大小相同且不重叠，以获得不同位置信息。

计算单元格的数量为 Cell-size。

3.1.3 视觉词袋特征

(1)SURF 特征描述子

SURF 具有稳定、快速的特点。具体的实现流程分为 5 个步骤：构建黑塞矩

阵、生成尺度空间、特征点定位、确定主方向、生成特征描述子。

SURF 特征使用黑塞矩阵表示图像，通过黑塞矩阵能生成的图像的极值点，

以用于后期的特征提取。构建黑塞矩阵首先需要高斯滤波器对图像进行处理。对

于图像 I 中的随机点 X  (x, y) 时，当尺度大小为 的黑塞矩阵为式（6）所示。

黑塞矩阵的判别式如式（7）所示。

L (x,) L (x,)

xx

xy

H(x,)

(6)

(7)

L (x,) L (x,)

yx

yy

Det(H)  L *L  L *L

yx

xx

其中 Lxx (x,)是高斯滤波器的二阶导数

得到 L (x,) ， L (x,) 和 L (x,) 。

yy

xy

2

g（）

与点 x 卷积的结果，同理可

x2

xy

yx

yy

SURF 算法中使用盒式滤波器取代了高斯滤波器[31]，盒式滤波器在滤波时只

13

福建医科大学硕士学位论文

需要通过积分图就可以很快的对图像进行滤波，此时的判别式如式(8)。

Det(H)  L *L 0.9*L *0.9*L

(8)

xx

yy

xy

yx

构建完成黑塞矩阵后，通过黑塞矩阵生成尺度空间。SURF 的尺度空间是若

干层组成，每组图像的盒式滤波器尺寸逐渐增大，同一组中的盒式滤波器模糊系

数依次变大，使用这种方法可以获取不同尺度的图像，构成了尺度空间。

在对特征点进行定位时，需要在尺度空间中查找极值点。SURF 算法中使用

了邻域非最大值抑制，预设一个极值，舍弃小于该值的像素点以减少计算量。在

初步确定了极值点后，由于该极值点是在离散空间中求出来的，与连续空间中的

真实极值存在一定差异，通常利用三维线性插值的方法来让该极值点靠近连续空

间上的真实极值。

在 SURF 算法中，通过统计特征点圆形邻域内的 Harr 小波特征来确定特征

点的主方向。设特征点的尺度为 r ，邻域为以 6 倍尺度作为半径的圆，计算邻域

内的点在 x 和 y 方向的 Har 小波(边长 4 r )响应，随后对这两个值高斯加权，加权

因子为 2 r 。选定一个夹角为 60°扇形区域，对区域内的小波响应分别求和，得

到一个新的向量。以一定间隔旋转扇形区域并重新统计响应值，求出所有响应值

中最大的那个向量，此时该向量方向即为主方向。

经过上述步骤，可以得到特征点的空间坐标和主方向，这些特征点都是图像

中比较突出的像素点，并且具有旋转不变尺度不变的特性。接下来根据这些特征

点的空间位置和主方向生成特征描述子，具体做法为：在这些特征点周围划分正

方形区域，并在这些区域中进行采样。正方形的大小根据需要提取特征维数来确

定，特征较少时会分类效果较差，而特征过多又会增加计算开销。特征维数与正

方形大小以及采样种类关系如式(9)：

N  a*a*

(9)

其中 N 是提取的特征总维数，a 是正方形的边长，边长的单位距离为 s (尺

度)， 是采样种类的数量。通常根据上述可得到 64 或 128 维特征描述子。

(2)BOW 视觉词袋

BOW 最初被用在文本分类中[32]，在计算机视觉的应用领域自然语言处理方

面得到了广泛的应用。它的基本思想是假定对于一个文本，忽略其词序和语法、

14

福建医科大学硕士学位论文

句法，仅仅将其看做是一些词汇的集合，而文本中的每个词汇都是独立的。在图

像领域，人们逐渐发现图像转换后即为矩阵或向量，便可看作为 BOW 的词汇表

达[33]，要将图像表示为 BOW 的向量，首先就是要得到图像的“词汇”。通常需

要在整个图像库中提取图像的局部特征，然后使用聚类的方法，合并相近的特征，

聚类的中心可以看着一个个的视觉词汇，视觉词汇的集合构成视觉词典。得到视

觉词汇集合后，统计图像中各个视觉词汇出现的频率，就得到了相应的 BOW 表

达。

3.1.4 特征融合和特征选择

在特征提取阶段结束后，每张图都能提取上部分的三个特征向量分别为

1*M，1*N 和 1*P，1 代表的为图片数量，M、N 和 P 代表的是上述三种特征提

取方法提取出来的特征向量。特征融合有三种融合情况，分别是在特征层、特征

分数层和分类层对特征进行融合。本文采取的是特征层处融合，未采取特征分数

层融合的原因是归一化后实验效果不佳，未采取分类层的原因是该方法对实际验

证结果影响较大。本文采取的是对上述三个特征向量进行串联操作，最终将单张

图片提取到的特征变成了 1*（M+N+P）的复合型特征向量后，采取了主成分分

析法[34]降维进行了特征选择，以便去除那些冗余的特征，从而加快训练速度和降

低测试时间，提高本模型的效率。

3.1.5 训练多分类模型

SVM[35]作为传统方法中分类效果最佳的分类器之一，在目标识别、分类领

域拥有着不可撼动的地位。SVM 是利用统计学习理论和结构风险最小化原理来

寻找全局最优解。传统的 SVM 是一种二分类的模型，它是将所提供的的特征向

量映射到一个平面，目的是为了找到最好区分两类的超级平面，从而将两类进行

分类。而本文研究的是五分类的问题，所以采取的是一对多方案，先将一类作为

A，其余类作为 B；依次实验五次后得到五个二分类的 SVM 分类器，组合后达

到五分类的目的。

y : w xi + b = 0

T

（10）

i  0,1,2...........n

15

福建医科大学硕士学位论文

上式中 w 代表加权向量，xi 代表输入的向量，T 代表对向量进行转置，b 代

表偏置参数。SVM 的主要目的是为了找到最优的加权向量 w ，从而找到最好区

分两个类的超平面系数。

3.2 基于深度学习的胎儿超声心脏标准五切面自动识别和分类模

型的构建

第二部分采用 DL，根据 ISUOG 与中国胎儿心脏超声检查指南相应超声指

南建立了一套更完善的胎儿心脏超声标准切面图像标注方案，在此基础上提出了

一种基于 SIOU 模块的 YOLOv5[36-38]高性能胎儿心脏标准切面 AI 识别模型

（U-Y-Net），实现对胎儿心脏超声标准切面解剖结构的自动识别[39]，从而定位

各种胎儿心脏超声标准切面。具体的实验流程图如图 3 所示。

此外，后期增加了模型对比实验，将第二部分所建立模型与现阶段已成功应

用于胎儿心脏标准切面的深度学习模型进行比较。并增加了不同等级医师与

U-Y-Net 的切面识别能力的临床检验实验，探究 U-Y-Net 对胎儿心脏标准超声切

面的识别能力。

图 3 模型构建流程图：图像预处理后进行模型构建及模型验证

Figure 3 Flow chart of model construction: Model construction and model verification after image

preprocessing

3.2.1 数据预处理

16

福建医科大学硕士学位论文

4CH 是评估胎儿心脏最基本的切面，提供了大量重要信息。标准 4CH 中，

两个心房和两个心室看起来大小大致相等，可见二尖瓣和三尖瓣、以及室间隔、

房间隔和卵圆孔，心室壁的厚度应该大致相等[40]。通过观察 4CH 的结构可判断

是否有单心室、左室发育不良、VSD 等先天性心脏缺陷。然而，仅依靠 4CH 难

以看到孤立的流出道病变，可通过联合判断 RVOT 中右心室（Right Ventricle，

RV）、升主动脉（Ascengding Aorta，AA）以及上腔静脉（Superior Vena Cava，

SVC），LVOT 中左心房（Left Atrium，LA）、左心室（Left VentricleLV，）、

主动脉（AortaAO，）与 RV 的结构及位置辅助筛查流出道病变如圆锥排列不齐、

ASD、半月瓣异常、主动脉缩窄、法洛四联症、大血管转位等病变[41]。但是流出

道切面的观察和获得不仅依赖于超声医师的操作水平，还依赖于胎位等因素。当

难以获得流出道切面时，3VV 和 3VT 提供了评估流出道异常的另一种方法,并在

技术上更容易进行。3VV 包括了肺动脉（Pulmonary Artery，PA）、AA，其中

PA 呈“Y”型分叉；3VT 包括了 AO、主肺动脉（Main Pulmonary Artery，MPA）

以及 SVC 横切面，SVC 后方有气管（Trachea，T）[9][22]。RVOT 和 3VT 的区别

主要在于主动脉弓和 T，两者的存在有助于更好地识别导管依赖性病变。3VT 以

T 为参考点，帮助识别和比较血管。因此本研究选取了这五个标准切面为研究对

象，标准结构如表 2 及图 4 所示。

图 4 标准切面与解剖结构标注示意图：A 超声标准五切面；B 切面图各解剖结构标注;C

17

福建医科大学硕士学位论文

各切面完整标注图

Figure 4 Schematic diagram of standard sections and anatomical structure annotation: A. five

dimensions of standard ultrasonic section;B.Section diagram of each anatomical structure

annotation;C.Complete annotation Map of each section surface.

3.2.2 胎儿心脏识别网络构建

(1) 网络架构

本文的胎儿心脏识别网络基于 YOLOv5，详细结构如图 5 所示。它主要由

Input 输入层，Backbone 主干网络层，Neck 中间层和 Prediction 预测层组成。Input

输入层部分用于图像输入和数据预处理。Backbone 主干网络层负责不同图像的

聚合和图像特征的形成。Neck 中间层包含一系列混合和组合的图像特征，并将

它们传递给Prediction预测层。Prediction预测层预测图像特征并生成预测边界框。

图 5 胎儿心脏识别模型网络构建：经过标注后的图像，从左至右输入到 YOLOv5 模型，

经过卷积神经网络，提取到深度特征，输出图像的关键信息

Figure 5 Construction of a model network for fetal heart recognition: The annotated image,

input from left to right to the YOLOv5 model, through the convolutional neural network, extracts

to the depth features to output the key information of the image

胎儿心脏识别网络的 Backbone 主干网络层是 CSPArknet 网络。它主要由

Focus、卷积标准化激活函数结构(Convolutional Batch-Normalization SiLU，CBS)、

CSP1_X、CSP2_X、空间金字塔池化层（Spatial Pyramid Pooling，SPP）。

18

福建医科大学硕士学位论文

①Focus 组件

从图 5 中可以看出，主干的第一层是 Focus，它通过 Slice 切片堆叠图像的

四个相邻位置，以减少原始信息的丢失，加快计算速度。然后进行 Concat 连接

层 融 合 。 CBS 块 形 成 为 卷 积 层 ， 然 后 是 批 处 理 归 一 化 批 标 准 化

（Batch-Normalization，BN）层和 Sigmoid 激活函数（Sigmoid Linear Unit，SiLU），

YOLOv5 的 Focus 组件如图 6 所示。

图 6 YOLOv5 的 Focus 组件

Figure 6 The Focus components of YOLOv5

②CSP 组件

YOLOv5 网络主要应用了两种 CSP 结构，分别是 CSP1_X 和 CSP2_X。

CSP1_X 表示该模块包含 x 个瓶颈，CSP2_X 表示该模块第一行的第二个 CBS 包

含 2*X 个瓶颈。该网络通过两个 CSP 结构将梯度变化整合到特征图中，解决了

其他网络中梯度信息重复和梯度消失的问题，在保证精度和速度的同时有效减少

了网络参数量，YOLOv5 的 CSP 组件如图 7 所示。

图 7 YOLOv5 的 Focus 组件

Figure 7 The Focus components of YOLOv5

③SPP 组件

SPP 模块主要由 CBS 块和 Max-Pool 最大池化层组成。输入端依次通过 CBS

块和三个 3×3、5×5、7×7 核的并行 Max-Pool 最大池化层，然后进行 Concat

连接层融合，有效增加图像特征的大小范围，YOLOv5 的 SPP 组件如图 8 所示。

19

福建医科大学硕士学位论文

图 8 YOLOv5 的 SPP 组件

Figure 8 The SPP assembly of YOLOv5

④BN 层和 SiLU 激活函数

利用 BN 层对卷积层后的特征映射进行归一化，加速网络学习，也具有一定

的正则化效果。在训练过程中，BN 需要学习一个小批数据的均值、方差，然后

使用这些信息进行归一化。在推理过程中，为了加速，将 BN 集成到其上卷积中，

并将两步操作转化为一个步骤来实现加速的目的。YOLOv5 所实现的是参数重构

的少量内容，即将卷积层和 BN 层合并成一个新的卷积层，但也包含 BN 层的特

征。

YOLOv5 中的 SiLU 本质上是将 Rectified 线性激活函数（Rectified Linear

Unit，ReLU）非绑定、平滑、非单调地加入到 Sigmoid 激活函数中，因此 SiLU

是 Sigmoid 和 ReLU 的改进版本。SiLU 在深度模型上的表现优于 ReLU。

⑤金字塔结构

在本文中，特征金字塔网络（Feature Pyramid Network，FPN）加上路径聚

合网络（Path Aggregation Network，PAN）结构在胎儿心脏识别网络的 Neck 中

间层采用。FPN 结构通过上采样传递和融合高级特征信息，而 PAN 结构将强定

位特征从底部传递到顶部。我们结合这两种结构在不同的检测层上进行特征聚

合，然后生成不同尺度的特征图，用于检测特定尺度上的目标。最后，在四个不

同的尺度上生成区域状态，它们的大小分别是原始输入图像大小的高宽的 1/8、

1/16、1/32、1/64，并将对应的特征图组合成有效检测不同大小的结构。

(2) 损失函数

在训练过程中，优秀的损失函数对结果的影响至关重要，本文模型将损失函

数定义为三部分，公式如下：

L  a*LCLS b*LOBJ  c*LBOX

(11)

20

福建医科大学硕士学位论文

LCLS 代表的是类别损失函数，表示预测框 i 中是否存在 j 类型的目标，如果

存在则等于 1，否则等于 0。 xij 为预测输出值， Npos 为正样本数。公式如下：

1

LCLS

(y log(sigmoid(x )) (1 y )log(1 sigmoid(x )) )

ij ij ij ij

Npos

(12)

LOBJ 代表目标置信度损失函数，由正样本匹配得到的样本对计算，一是预

测框中的目标置信度分数；二是预测框和与之对应的目标框的 IOU 值，其作为

ground-truth。LOBJ 表示预测框和 GT 框的重叠程度，xi 是网络对当前目标的预测

值， N 是正负样本数之和。两者计算二进制交叉熵得到最终的目标置信度损失。

公式如下：

1

LOBJ   (y log(sigmoid(x )) (1 y )log(1 sigmoid(x )))

i

i

i

i

N

(13)

LBOX 代表的是 bounding box 回归损失函数，在原始的 YOLOv5 模型中采用

的是 CIOU 损失函数。本文中采用 SIOU 作为 LBOX ，SIOU 引入真实框和预测框

之间的向量角度，重新定义相关损失函数。

SIOU 损失函数由以下 4 个 Cost 函数组成：

1）角度损失(Angle cost）

其中，Angle cost 的曲线如图 9 所示，定义如下。

图 9 Angle cost 的曲线

21

福建医科大学硕士学位论文

Figure 9 The curve of the Angle cost

c

c

h

4

1 2*sin

2

arcsin

h

cos 2*arcsin

4

(14)

其中ch 为真实框和预测框中心点的高度差， 为真实框和预测框中心点的距

c

离，事实上 arcsin

h

等于角度 。

c

h  sin()

(15)

2

2

bgt  b   bgt  b

c

c

c

c

x

x

y

y

(16)

(17)

gt

gt

cy

c  max b ,b  min b b

h

c

cy

c

y

y

其中bcgt b 为真实框中心坐标bgt b 为预测框中心坐标，可以注意到当

c

cx

c

x

y

y

为π/2 或 0 时，角度损失为 0，在训练过程中若 <π/4，则最小化为 ，否则

为  。

2)距离损失(Distance cost)

Distance cost 的曲线如图 10 所示，定义如下：

图 10 Distance cost 的曲线

Figure 10 The curve of the Distance cost

1e pt  2e px e py

tw,h

(18)

22

福建医科大学硕士学位论文

其中：

2

2

bcgt bc

bcgt bc

px

x

x

, p

y

y

,  2

y

cw

ch

(19)

上述这里的c ，c 为真实框、预测框最小外接矩形的宽和高。

w

h

3)形状损失(Shape cost)

Shape cost 定义如下：

1 ewt   1 eww   1 ewt

tw,h

(20)

(21)

其中：

w wgt

h  hgt

ww

,wh

max w wgt

,

maxh,hgt

w,h，wgt ,hgt 分别为预测框、真实框的宽和高，控制对形状损失的关注

程度。为了避免过于关注形状损失而降低对预测框的移动，本阶段使用遗传算法

计算出 接近 4，所以 参数范围为[2，6]。

4)IOU 损失(IOU cost)

具体的如图 11 所示。两个区域的重叠面积与面积的并集（或面积的最大者、

面积的最小者）的比值：

图 11 IOU 损失

Figure 11 A is shown for IOU loss

综上四种 Cost 函数所诉，最终 SIOU 损失函数定义如下：

LBOX 1 IoU

2

(22)

23

福建医科大学硕士学位论文

4 统计学处理

应用 SPSS 24.0 软件进行统计学分析。计量资料用均数±标准差（

）

表示，符合正态分布使用 t 检验或方差分析；计数资料以例（n）或率（%）表

示，组间比较采用 2 检验，以 p＜0.05 认为差异具有统计学意义。

第一部分及第二部分通过精确率（Precision）、召回率（Recall）、综合评

价指标（F1 分数）、准确率（Accuracy）对模型进行评估，计算公式定义如下：

TP

Precision=

TP  FP

（23）

（24）

（25）

（26）

TP

Recall=

TP  FN

2 Precision Recall

Precision+Recall

F1

TP TN 100%

TP TN  FP  FN

Accuarcy

真阳性（True Positive，TP）：经试验而被正确分类的数目；假阳性（False

Positive，FP）：经试验而被错误分类的非本类的数目；真阴性（True Negative，

TN）：经试验而被正确分类的非本类的数目；假阴性（False Negative，FN）：

经试验而被错误分类的数目。通过公式可知精确率相当于阳性预测值，召回率相

当于灵敏度。下文用阳性预测值及灵敏度代替精确率及召回率。

F1-分数为阳性预测值和灵敏度的加权调和平均，是二分类模型中常用的一

个综合评价指标，能够均衡阳性预测值和灵敏度之间的矛盾而更加客观的评价模

型性能的优劣，其值介于 0~1 之间，F 值越高证明模型越有效。

应用准确率、阳性预测值、灵敏度、F1-分数评价 LH-BOW 的性能。应用

Map 值、准确率、阳性预测值、灵敏度、特异度、F1-分数评价 U-Y-Net 的性能。

U-Y net 与初级医师、中级医师对标准超声心脏五切面的临床检验能力采用

McNemar 检验。

24

福建医科大学硕士学位论文

结果

1 基于传统手工特征模型的实验结果

1.1 LH-BOW 对不同心脏标准切面的识别效果

LH-BOW 对胎儿心脏标准切面的整体识别准确率达 89.60%，平均阳性预测

值达到 89.71%，平均灵敏度达到 89.60%，F1 分数在 0.85~0.96 之间。F1 分数最

好的为 4CH 95.05%，其次为 3VV 92.78%，3VT 表现最差，但识别效果均在 85%

以上（表 3）。在测试集的识别结果中，3VT 易错误识别为 RVOT，RVOT 识别

成 3VT，3VV 主要是识别成 LVOT（图 12）。

表 3 LH-BOW AI 模型识别结果

Table 3 Results of the LH-BOW AI model identification

切面类型

3VV

准确率（%）

阳性预测值（%） 灵敏度（%）

F1-分数

0.9278

0.8571

0.9505

0.8600

0.8846

0.8960

0.9574

0.8750

0.9412

0.8600

0.8519

0.9000

0.8400

0.9600

0.8600

0.9200

3VT

4CH

RVOT

LVOT

图 12 LH-BOW 对测试集识别分类结果的混淆矩阵图：3VV 中 45 张、3VT 中 42 张、4CH

中 48 张、ROVT 中 43 张、LVOT 中 46 张被正确识别分类

Figure 12 LH-BOW: 45 in 3 VV, 42 in 3VT, 48 in 4 CH, 43 in ROVT and 46 in LVOT were

correctly identified and classified

25

福建医科大学硕士学位论文

1.2 LH-BOW与不同 AI自动识别模型的心脏标准切面识别效果

对比

本研究将 LH-BOW 模型分别与其余已知模型进行性能对比实验，LH-BOW

模型的准确率、阳性预测值、灵敏度与 F1-分数比 LBP 模型、HOG 模型、

SURF-BOW 词袋模型、LBP-HOG、LBP+HOG+GLCM 模型、Sono-net32 模型更

佳（p=0.01）（表 4）。

表 4 不同的模型结果的对比

Table 4 Comparison of the different model results

模型

准确率

切面类型

3VV

阳性预测值

0.8718

0.6471

0.8269

0.5455

0.7867

0.8781

0.6863

0.9375

0.5588

0.8333

0.7500

0.7143

0.8958

0.6792

0.8542

0.9000

0.8421

0.8000

0.7083

0.8333

灵敏度

0.6800

0.6600

0.8600

0.7200

0.6600

0.7200

0.7000

0.9000

0.7600

0.7000

0.7800

0.7000

0.8600

0.7200

0.8200

0.9000

0.7619

0.8696

0.7727

0.7143

F1-分数

0.7640

0.6535

0.8431

0.6207

0.7174

0.7912

0.6931

0.9184

0.6441

0.7609

0.7647

0.7071

0.8776

0.6990

0.8367

0.9000

0.8000

0.8333

0.7390

0.7692

3VT

LBP

0.7160

4CH

RVOT

LVOT

3VV

3VT

HOG

0.7560

0.7760

0.8240

4CH

RVOT

LVOT

3VV

3VT

SURF-BOW 词袋模

4CH

型

RVOT

LVOT

3VV

3VT

LBP-HOG

4CH

RVOT

LVOT

26

福建医科大学硕士学位论文

续表 4 不同的模型结果的对比

Table 4 Comparison of the different model results

模型

准确率

切面类型

3VV

阳性预测值

0.8846

0.7955

0.9600

0.7692

0.8654

0.8696

0.7619

0.8333

0.6842

0.8039

0.9574

0.8750

0.9412

0.8600

0.8519

灵敏度

0.9200

0.7000

0.9600

0.8000

0.9000

0.8000

0.6400

0.9000

0.7800

0.8200

0.9000

0.8400

0.9600

0.8600

0.9200

F1-分数

0.9020

0.7447

0.9600

0.7843

0.8924

0.8333

0.6957

0.8654

0.7290

0.8119

0.9278

0.8571

0.9505

0.8600

0.8846

3VT

LBP++HOG+GLCM

0.8560

4CH

RVOT

LVOT

3VV

3VT

Sono-net32

0.7880

4CH

RVOT

LVOT

3VV

3VT

LH-BOW

0.8960

4CH

RVOT

LVOT

2 基于深度学习模型的实验结果

2.1 U-Y-Net 模型对每个解剖结构的识别结果

U-Y-Net 对胎儿心脏标准切面的整体识别 Map 值达到 94.3%，整体 F1 分数

为 0.9277。平均阳性预测值 94.60%，平均灵敏度 91.0%，F1 分数在 0.82~0.99

之间,特异度在 99.2%~93.7%之间。识别效果最好的是 4CH，Map 达到了 99.5%，

阳性预测值为 99.5%，灵敏度为 100%，特异度为 99.2%，F1 分数达到了 0.9975。

其次是 LV，Map 达到了 99.5%，阳性预测值为 99.2%，灵敏度为 100%，特异度

为 98.4%，F1 分数达到了 0.9959。效果最差的为 T，Map 为 86.9%，阳性预测值

为 90.9%，灵敏度为 75.5%，特异度为 97.2%，F1 分数仅有 0.8249（图 13，表 5）。

从结果分析可得，所有解剖结构的识别效果均在 85%以上。

27

福建医科大学硕士学位论文

图 13 U-Y-Net 对测试集解剖结构识别分类结果的混淆矩阵图

Figure 13 Confusion matrix plot of the classification results of U-Y-Net

表 5 U-Y net 对每个解剖结构的识别结果

Table 5 U-Ynet identification results for each anatomical structure

解剖结构

4CH

LV

Map（%）

99.5

阳性预测值（%） 灵敏度（%） F1 分数

特异度（%）

99.2

99.5

99.2

95.0

90.0

92.2

93.7

99.2

93.9

92.5

90.9

94.6

100

100

0.9975

0.9959

0.9348

0.8847

0.8796

0.9139

0.9366

0.9513

0.9460

0.8249

0.9277

99.5

98.4

LA

97.9

92.0

87.0

84.1

89.2

88.7

96.4

96.8

75.5

91.0

98.4

AO

90.3

93.7

RV

89.4

96.5

AA

94.2

97.4

SVC

PA

95.1

97.9

94.8

99.6

MPA

T

95.7

97.2

86.9

97.2

All

94.3

28

福建医科大学硕士学位论文

2.2 模型对比实验

由于 U-Y-Net 是在 YOLOv5 为基础框架模型上进行改进，所以与原始的

YOLOv5 及现在常用的深度学习模型进行了对比。实验环境在同一环境和相同数

据集情况下进行对比实验，表 6 显示的是本文模型与 Fast-RCNN&Mobilenetv2，

Fast-RCNN&Res-Net50，RetinaNet&Res-Net50，SSD&Res-Net50，VGG-Net 等一

众 tow tage 网络和 one tage YOLOv5 模型的对比。在 Map 上 U-Y-Net 取得了 94.3%

的 效 果 ， 相 较 tow tage 深 度 学 习 Fast-RCNN&Mobilenetv2 ，

Fast-RCNN&Res-Net50，RetinaNet&Res-Net50，SSD&Res-Net50，VGG-Net 等一

众 方 法 ， U-Y-Net 各 项 评 价 指 标 大 幅 度 领 先 各 个 模 型 ， 其 中 最 好 的

Fast-RCNN&Mobilenetv2 在 Map 上结果也仅能达到 81.2%。U-Y-Net 比 YOLOv5

的 Map 值提高 0.9%（p＜0.05）。

表 6 不同模型的对比实验

Table 6 Contrasting experiments with the different models

模型

Map(%)

81.20

阳性预测值(%) 灵敏度(%)

F1 分数

Fast-RCNN&Mobilenetv2

84.20

77.60

81.40

60.40

74.20

94.90

94.60

82.20

80.20

83.80

72.20

86.40

92.70

91.00

0.8318

Fast-RCNN&Res-Net50

RetinaNet&Res-Net50

SSD&Res-Net50

VGG-Net

75.60

77.40

66.20

79.60

93.40

94.30

0.7888

0.8258

0.6577

0.7983

0.9379

0.9277

YOLOv5

U-Y-Net

2.3 不同医师与 U-Y-Net 之间的对比实验

U-Y-Net 识别 4CH、3VV、3VT、LVOT 的灵敏度高出初级医师，识别 3VV、

RVOT、LVOT 的准确率高于初级医师。U-Y-Net 在整体切面的识别上准确率、

灵敏度值均高于初级（p＜0.05），与中级相当（表 7）。

29

福建医科大学硕士学位论文

表 7 不同医师与 U-Y-Net 之间的对比实验结果

Table 7 Experimental results between different physicians and U-Y-Net

切面

方法

灵敏度(%)

特异度(%)

阳性预测值(%)

准确率

(%)

4CH

初级医师

中级医师

U-Y-Net

90.28

95.83a

98.6a

38.89

55.56

33.33

20.00

40.00

40.00

19.35

16.67

25.81

50.00

70.00

80.00

52.38

71.43

76.19

63.56

51.35

58.95

83.87

89.61

85.45

88.24

92.11

92.50

73.40

80.00

77.45

73.40

92.68

95.29

84.62

92.11

93.15

83.66

88.93

91.90

80.00

87.78

85.00

68.13

81.32a

85.71a

65.79

73.68

76.32

71.43

80.36

86.61a

64.08

82.52a

81.55a

71.17

82.80a

83.17a

3VV

3VT

初级医师

中级医师

U-Y-Net

74.07

86.41a

91.36a

74.07

96.39a

97.53a

76.09

82.61

88.04

66.27

85.37a

82.92a

79.67

90.04a

87.72a

初级医师

中级医师

U-Y-Net

RVOT

LVOT

整体

初级医师

中级医师

U-Y-Net

初级医师

中级医师

U-Y-Net

初级医师

中级医师

U-Y-Net

注：a：与初级比较，p＜0.05。

30

福建医科大学硕士学位论文

讨论

CHD 占先天性出生缺陷的首位，每年影响着成千上万的家庭。据报道，CHD

可导致 42%的婴幼儿死亡,是婴幼儿死亡的首要原因[42]。即使在成人心脏病中，

CHD 仍占据着很大的比例。面对 CHD 所带来的经济压力、对公共卫生资源造成

的负担以及对家庭的打击，社会对早期诊断 CHD、提高 CHD 的检出率的要求愈

发强烈。然而心脏发育是一个复杂的过程，从单一的心管发展发育成具有四个腔

室和各流出道的心脏，这期间任何一步的异常都有可能导致 CHD 的发生[43]。超

声检查是重要的产前检查方法，在产前筛查方面具有不可替代的作用。通过超声

检查能够对大部分胎儿畸形进行观察及诊断，特别是对于 CHD 而言，产前超声

检查显得尤为重要[44]。超声检查相较于 CT、磁共振等检查方法，它具有价格低

廉、无辐射、可重复性强、操作方便、耗时较短等优势。因此，超声检查成为了

产前心脏筛查的首选检查手段，它能在胎儿心脏发育的不同阶段对胎儿心脏的发

育发展做出评估以及诊断，为临床医生在后续的诊疗过程提供一定的帮助。

识别并获取胎儿心脏超声标准切面对于产前超声心脏筛查是最为关键的一

步[45]。目前，胎儿心脏超声标准切面的获取尚未实现自动化，仍需依靠超声医师

人为识别、手动获取。但在现实的临床超声筛查工作中，心脏标准切面的识别获

取受到多种因素的影响。例如胎儿心脏结构复杂、体积较小、毗邻器官多、血流

动力学与成人不同等[46],加上每个医生资质不一、地区医疗水平不同、医院设备

不同、对心脏标准切面的认知存在差异，也会导致扫查工作中耗费资源过多。以

上诸多因素都会使得检查时间增加、图像质量不一、识别准确率受限。

随着科技的发展，AI 逐渐进入人们的视线。智慧医疗也成为了当前研究的

热点。目前智慧医疗主要体现在辅助诊断[47-48]、筛查病例、健康监测等方面。与

常规的医疗过程相比，AI 技术参与的智慧医疗显著降低了人力物力成本、减轻

了临床工作对医师的负荷、有效帮助医师更好的开展临床工作。在日常的超声诊

疗过程中，数据的产生往往庞大而复杂，在众多信息中筛选并获取想要的结果常

需要耗费大量的精力和时间，而超声的图像特点及超声医师的工作性质，展示出

AI 与超声结合的前景及可行性。

因此，本文先后提出两种 AI 识别方法[39,49]，能更快、更准确地识别胎儿心

脏的标准切面。本文的两种识别方法无论在胎儿切面的整体识别还是在局部的解

31

福建医科大学硕士学位论文

剖结构识别中都取得一个满意的结果，并优于目前常用于图像识别的 AI 模型，

充分展示出本文模型的优势。说明这两种识别方法具有一定的潜能，未来或可用

于临床，帮助医师识别获取心脏标准切面、有益于医师心脏产前超声培训、提高

心脏标准切面图像的质量。

本研究第一部分的结果表明在相对有限的数据量下，LH-BOW 识别性能是

优异的。利用具有灰度不变性的 LBP 和具有方向不变性的 HOG 进行图像纹理特

征提取的方法解决超声图像中普遍存在成像问题和角度问题，并且 LBP-HOG 的

方法已被证实适用于超声胎儿的其它标准切面[50]，在 LBP-HOG 基础上本文添加

了 BOW 用以解决超声探头扫查和后期成像所带来的图像尺度大小不一的问题，

而 SURF 是一种当图像发生旋转、尺度改变等变换后提取到的特征仍保持不变图

像局部特征描述算法[51]，增加 SURF 可进一度提高了分类的准确性，最后利用分

类算法对提取的特征进行分类。SVM 是以结构风险最小化原则为基础，不仅能

够很好的解决了有限数量样本的构造模型问题，并且构造的模型具有很好的泛化

能力。本研究结果发现 LH-BOW 在有限样本量下识别性能优于单个模型及现如

今已成功应用于胎儿心脏标准切面的深度学习模型。

相比较深度学习方法 Sono-Net32，LH-BOW 各项评价指标除在 4CH 切面上

略低于 Sono-Net32 外，在其余四个切面都有所提高。在分类过程中，本文和

Sono-Net32 出现了同样的问题，针对 3VT 和 RVOT 切面都出现了精确率下降的

问题。分析原因主要有 4CH 整体结构容易辨认，由四个独立的房和室组成，相

较于其它四个切面，模型所需要提取的特征更具有对比性和象征性，虽然中期训

练 Sono-Net32 需要花费大量时间，但是由于深度学习的特点，Sono-Net32 更像

个黑匣子，能提取到更为丰富的深度特征，这一点是 LH-BOW 不能媲美的。其

次通过图 1 可以观察到 3VT 和 RVOT 存在着相似的解剖结构，这导致实验模型

在真实分类时出现了误判的情况。3VT 的主要解剖结构组成是主肺动脉，升主动

脉，上腔静脉，RVOT 主要解剖结构组成是主肺动脉，主动脉弓，上腔静脉组成，

这两个切面的相似度非常高，在日常工作中常需动态观察用于区别，而静态图像

易于混淆。

深度学习中的卷积神经网络（Convolutional Neural Network，CNN）采用原

始图像(或大块图像)作为输入，不仅避免传统识别算法中复杂的特征提取，也减

32

福建医科大学硕士学位论文

少了在人工上的花费。CNN 对于平移、缩放、倾斜和其他形式的变形具有高度

不变性。它为图像处理带来了重大突破，现广泛应用于各种计算机视觉图像任务

中[52-53]。本研究的第二部分在持续扩大数据后，通过对 ISUOG 相关超声指南的

解读和讨论，提出一个利用识别各标注切面的具体解剖结构来定位胎儿心脏超声

标准切面的方案。基于 DL 构建识别模型 U-Y-Net 来提高对胎儿心脏超声标准切

面的识别准确率。实验结果表明 U-Y-Net 比现常用的深度学习模型性能更佳，但

相较于 YOLOv5，U-Y-Net 仅在 Map 上略微领先 0.9%，在其余的评价指标上有

些许下降。分析原因主要是由于 tow tage 的网络模型对大目标的识别效果较佳，

而在针对胎儿心脏超声解剖结构这一类数据时，因为胎儿心脏各个标准切面相

似，同处于一个圆形的心脏内部，不同点主要在于各个小目标，YOLOv5 模型能

够很好的识别小目标，并且针对小目标能较好的与周围的信息进行交互，所以在

胎儿心脏标准切面解剖结构识别任务上 YOLOv5 模型大幅度领先两阶段的网络

模型。其次上文提到角度信息，在超声胎儿心脏标准切面扫查的过程中，由于超

声医师扫查手法的不同，导致扫查到的不同切面的解剖结构位置各异，本文所利

用的 SIOU 损失函数能更好的注意角度信息[54]，所以 U-Y-Net 比原始 YOLOv5

效果更好。实验证明 U-Y-Net 能有效的识别心脏的几个重要结构，对心脏超声标

准五切面分类效果良好。不仅优于原始的 YOLOv5 也优于现在常用的深度学习

模型，在与不同资质的医师对比中我们发现 U-Y-Net 的识别效能与中级医师相

当。

本文尚有部分不足之处，这也将会是后期研究的目标：传统的手工分类特征

是一种半监督方式的学习方法。需要人为的事先对输入图像进行处理、筛选图像

感兴趣区域、再利用特征提取算法提取图像特征、最后选择分类算法对提取的特

征进行分类[55]。需要人为参与的方式使其时间花费较大、易造成窗口冗余，图像

质量的不确定性也会影响它的效果[56-57]。如何降低时间花费，减少窗口的冗余，

提高图像质量是后续研究方向之一。而气管在诸多结构中的识别效果相对较差，

如何更好的提高识别效能、增加相应的测量功能、计算各结构的位置关系将会是

后期的研究重点。为达到更好辅助超声医师诊断的作用，后期也会继续收集正常

胎儿心脏相应的超声切面数据以扩大胎儿心脏超声标准切面数据库，训练并优化

AI 模型。本文实验所采用的数据均源于产后证实无任何畸形产生的胎儿，为了

33

福建医科大学硕士学位论文

先天性心脏缺陷提供更多信息，后期将增加超声检查所筛查出的先天性心脏缺陷

数据，用以训练模型的识别效能，做到利用模型辅助诊断 CHD。

34

福建医科大学硕士学位论文

结论

1. LH-BOW 在有限的样本量中能有效的识别分类胎儿心脏标准五

切面，可能帮助医师减少胎儿心脏产前筛查工作的负荷。

2. U-Y-Net 能识别胎儿心脏的诸多重要结构，不仅具有辅助医生识

别分类标准切面的作用，还具有帮助医生筛查 CHD 的潜在价值。

综上，本文所提出的模型能有效地识别和分类胎儿心脏重要解剖结果以

及标准切面图像，为产前胎儿超声检查程序的自动标准化奠定了基础。在临

床工作中能有效地节省人力和时间，提高工作效率，同时也有望进一步为初

级资质的超声医师提供更简洁的培训学习方法。

35

福建医科大学硕士学位论文

参考文献

[1] Howell HB,Zaccario M,Kazmi SH,et al.Neurodevelopmental outcomes of children

with congenital heart disease: A review[J].Current Problems in Pediatric and

Adolescent Health Care,2019,49(10):1-19.

[2]Williams K, Carson J, Lo C.Genetics of congenital heart disease [J].Biomolecules

2019,9(12):879-901.

[3]曹景颖,吴信,陈寄梅,等.坚守初心与使命——我国先天性心脏病事业的开创与

继承[J].中国心血管病研究,2021,19: 577-581.

[4] Lee MY,Won HS.Review: Technique of fetal echocardiography [J].Obstetrics and

Gynecology Science,2013,56(4):217-226.

[5] Rychik J,Ayres N,Cuneo B,et al.American society of echocardiography guidelines

and standards for performance of the fetal echocardiogram- sciencedirect[J].

American Society of Echocardiography,2004,17(7):803-810.

[6] Tan CM,Lewandowski A J.The transitional heart: from early embryonic and fetal

development to neonatal Life[J].Fetal Diagnosis and Therapy,2019,47(5):1-14.

[7] Freud LR,Tworetzky W.Fetal interventions for congenital heart disease [J].Current

Opinion in Pediatrics,2016,28(2):156-162.

[8] Bridge CP,Ioannou C,Noble JA.Automated annotation and quantitative description

of ultrasound videos of the fetal heart-science direct[J].Medical Image

Analysis,2017,36:147-161.

[9] ISUOG Practice Guidelines (updated): sonographic screening examination of the

fetal heart[J].The International Society of Ultrasound in Obstetrics and

Gynecology, 2013,41(3):348-359.

[10]徐燕,茹彤,胡娅莉,等.孕中期超声胎儿结构筛查在超声培训中的质量控制[J].

现代妇产科进展,2016,25:589-592.

[11]王丹,张瑾晖,王娟,等.人工智能和超声造影鉴别甲状腺 TI-RADS4~5 类结节中

乳 头 状 癌 和 结 节 性 甲 状 腺 肿 的 诊 断 价 值 [J]. 中 国 超 声 医 学 杂

志,2021,37(5):502-505.

[12]Liu XP,Yang X,Wu L.P,et al.Automatic search for the best cross-sections of the

three-dimensional ultrasound image of heart by template matching[J].Biomedical

Engineering,2008,25:491-496.

[13]Yi X,Babyn P.Sharpness-aware low-dose CT denoising using conditional

generative adversarial network[J].Digital Imaging,2017:1-15.

[14]霍宇欢,同文地,李昕,等.经食管超声心动图标准切面导航可视化系统设计与

实现[J].计算机应用,2015,35:212-215,241

36

福建医科大学硕士学位论文

[15]Madani A,Moradi M,Karargyris A,et al.Semi-supervised learning with generative

adversarial networks for chest X-ray classification with ability of data domain

adaptation[C]//2018 IEEE 15th International Symposium on Biomedical Imaging

(ISBI 2018),2018:1038-1042.

[16]Zhang Q,Wang H,Lu H,et al.Medical image synthesis with generative adversarial

networks for tissue recognition[C]//2018 IEEE International Conference on

Healthcare Informatics (ICHI),2018:199-207.

[17]Chen X, He M, Dan T,et al.Automatic measurements of fetal lateral ventricles in

2D

ultrasound

images

using

deep

learning[J].Frontiers

in

Neurology,2020,11:526.

[18]Xie HN,Wang N,He M,et al.Using deep learning algorithms to classify fetal brain

ultrasound images as normal or abnormal[J].Ultrasound in Obstetrics and

Gynecology,2020,56:579-587.

[19]Lei B,Tan E L,Chen S,et al.Automatic recognition of fetal facial standard plane in

ultrasound image via fisher vector[J].PLOS ONE,2015,10:1-20.

[20]Wang J,Liu F.X,Wang F,et al.Automated interpretation of congenital heart

disease from multi-view echocardiograms[J].Medical Image Analysis,2021:69.

[21]Lu X,Liu M.Y,Shen Z.R,et al.DW-Net: a cascaded convolutional neural network

for

apical

four-chamber

view

segmentation

in

fetal

echocardiography[J].Computerized Medical Imaging and Graphics,2019:80.

[22]中国医师协会超声医师分会,中国胎儿心脏超声检查指南[M]人民卫生出版

社,2018,4(1):7-13.

[23]Ojala T,Pietikainen M,Harwood D.A comparative study of texture measures with

classification based on featured distributions[J].Pattern Recognition,

1996,29:51-59.

[24]Adetiba E,Olugbara OO.Lung cancer Prediction using neural network ensemble

with histogram of oriented gradient genomic features[J].The Scientific World

Journal,2015:1-17.

[25]Bay H,Ess A,Tuytelaars T,et al.Speeded-up robust features (SURF)[J].Computer

Vision and Image Understanding,2008,110:346-359.

[26]Liu L,Chen J,Fieguth P,et al.From BOW to CNN: Two decades of texture

representation for texture classification[J].Computer Vision,2018;(127):74-109.

[27]Joachims T.Making large-scale SVM learning practical[J].Technical

Reports,1998,8:499-526.

[28]Wang T,Gardezi S J S,Elazab A,et al.Breast cancer detection and diagnosis using

37

福建医科大学硕士学位论文

mammographic data: systematic review[J].Journal of Medical Internet

Research,2019,21(7):e14464.

[29]Ohtake Y,Belyaev A G,Seidel H P.Mesh smoothing by adaptive and anisotropic

gaussian filter applied to mesh normals[C]//Proceedings of the Vision,Modeling

and Visualization Conference,2002,9:20-22.

[30]Patel C I,Labana D,Pandya S,et al.Histogram of oriented gradient-based fusion of

features for human action recognition in action video sequences[J].Sensors,

2020,20:7299.

[31]Dalal N,Triggs B.Histograms of oriented gradients for human detection[C]// 2005

IEEE Computer Society Conference on Computer Vision and Pattern

Recognition (CVPR'05), 2005,1: 886-893.

[32]Csurka G,Dance C,Fan L,et al.Visual categorization with bag of keypoints[C]//

European Conference on Workshop on Statistical Learning in Computer

Vision,2004:1-22.

[33]Juluru,Krishna,Shih,et al.Bag-of-words technique in natural language processing:

A primer for radiologists[J].Radiographics:A Review Publication of the

Radiological Society of North America, 2021,41(5):1420-1426.

[34]K.Esbensen,P.Geladi.Principal component analysis[J].Chemometrics and

Intelligent Laboratory Systems,1987,2(1-3):7-52,

[35]Joachims T.Making large-scale SVM learning practical[J].Technical Reports,

1998,8(3):499-526.

[36]Kim JU,Ro YM.Attentive layer separation for object classification and object

localization in object detection[C]//2019 IEEE International Conference on

Image Processing (ICIP). IEEE,2019:3995-3999.

[37]Xu Q,Zhu ZY,Ge HL,et al.Effective face detector based on YOLOv5 and

superresolution reconstruction[J].Computational and Mathematical Methods in

Medicine,2021:1-9.

[38]Luo Y,Zhang YF,Sun XZ,et al.Intelligent solutions in chest abnormality detection

based on YOLOv5 and resNet50[J].Healthcare Engineering,2021:1-11.

[39]Wu HL,Wu BZ,Lai FP,et al.Application of artificial intelligence in anatomical

structure recognition of standard section of fetal heart[J].Computational and

Mathematical Methods in Medicine,2023,2023:1-13.

[40]Yan JB,Yan XM,Yang JX,et al.Analysis of the clinical significance and the risk

factors of prenatal ultrasound screening for fetal congenital heart

disease[J].General Practice,2016,14(1): 114-115,160.

38

福建医科大学硕士学位论文

[41]Bishop KC,Kuller JA,Boyd BK,et al.Ultrasound examination of the fetal

heart[J].Obstetrical and Gynecological Survey,2017,72(1):54-61.

[42]Rosano A,Botto LD,Botting B,et al.Infant mortality and congenital anomalies

from 1950 to 1994: an international perspective.[J].Epidemiol Community

Health,2000,54: 660–666.

[43]Groot GD,Bartelings MM,Poelmann RE,et al.Embryology of the heart and its

impact on understanding fetal and neonatal heart disease[J].Seminars in Fetal

and Neonatal Medicine, 2013,18(5):237-244.

[44]周小雪,张莹莹,张烨,等.人工智能技术在胎儿超声心动图四腔心切面筛查中

的应用[J].中华超声影像学杂志, 2020,29(8):5.

[45]Hernandez-Andrade E, Patwardhan M, Cruz-Lemini M,et al.Early evaluation of

the fetal heart[J].Fetal Diagnosis and Therapy,2017,42(3):161-173.

[46]Fyfe DA,Kline CH.Fetal echocardiographic diagnosis of congenital heart

disease[J].Congenital Heart Disease,1990,37(1):45-67.

[47]叶冯颖,李尚青,苏淇琛,等.计算机辅助诊断系统基于不同指南诊断甲状腺良

恶性结节的对比分析[J].临床超声医学杂志, 2020, 22(9):694-696.

[48]叶冯颖,杨文敏,李尚青,等.计算机辅助诊断软件联合多学科建立甲状腺结节

恶性风险预测模型[J].中国医学物理学杂志, 2021,38(1):54-60.

[49]Wu BZ,Liu PZ,Wu HL,et al.An effective machine-learning based feature

extraction/recognition model for fetal heart defect detection from 2D ultrasonic

imageries[J].Computer Modeling in Engineering and Sciences,2022,

134(2):1069-1089.

[50]Wang XL,Liu ZH,Du YC,et al.Recognition of fetal facial ultrasound standard

plane based on texture feature fusion[J].Computational and Mathematical

Methods in Medicine,2021(70):1-12.

[51]Nawaz SA,Li J,Bhatti UA,et al.Advance hybrid medical watermarking algorithm

using speeded up robust features and discrete cosine transform[J].PLOS ONE,

2020,15(6): 1-21.

[52]Deng SJ,Zhang X,Yan W,et al.Deep learning in digital pathology image analysis:

a survey[J].Frontiers of Medicine, 2020,14(4):1-18.

[53]Singh J,Thakur D,Ali F,et al.Deep feature extraction and classification of android

malware images[J].Sensors,2020,20(24):7013.

[54]Han GJ,Li T,Li Q,et al.Improved algorithm for insulator and its defect detection

based on YOLOX[J].Sensors, 2022:1-14.

[55]许德刚,王露,李凡.深度学习的典型目标检测算法研究综述[J].计算机工程与

39

福建医科大学硕士学位论文

应用,2021,57(8):10-25.

[56]马原东,罗子江,倪照风,等.改进 SSD 算法的多目标检测[J].计算机工程与应

用,2020,56(23):23-30.

[57]凌晨,张鑫彤,马雷.基于 Mask R-CNN 算法的遥感图像处理技术及其应用[J].

计算机科学,2020,47(10):151-160.

40

福建医科大学硕士学位论文

附录

英文缩略词表

英文缩写

AA

英文全称

Ascengding Aorta

Artificial Intelligence

Aorta

中文全称

升主动脉

人工智能

主动脉

AI

AO

ASD

Atrial Septal Defect

房间隔缺损

BN

Batch-Normalization

Bag of Words

批标准化

视觉词袋模型

卷积标准化激活

函数

BOW

CBS

Convolutional Batch-Normalization SiLU

4CH

CHD

CNN

CPN

Four Chamber View

Congenital Heart Disease

Convolutional Neural Network

Class Prediction Network

心尖四腔心切面

先天性心脏病

卷积神经网络

类预测网络

电子计算机断层

扫描

CT

Computed Tomography

DL

FP

Deep Learning

False Positive

深度学习

假阳性

FPN

FN

Feature Pyramid Network

False Negative

特征金字塔网络

假阴性

HOG

IP

Histogram of Oriented Gradient

Intermediate Physician

International Society of Ultrasound in

Obstetrics and Gynecology

Junior Physician

方向梯度直方图

中级医师

国际妇产科超声

学会

ISUOG

JP

LA

初级医师

Left Atrium

左心房

LBP

Local Binary Pattern

局部二值模式

41

福建医科大学硕士学位论文

LVOT

LV

Left Ventricular Outflow Tract

Left Ventricle

左室流出道切面

左心室

MPA

PA

Main Pulmonary Artery

Pulmonary Artery

主肺动脉

肺动脉

PAN

Path Aggregation Network

路径聚合网络

Rectified 线性激

活函数

ReLU

Rectified Linear Unit

RPN

RV

Region Proposal Network

Right Ventricle

区域建议网络

右心室

RVOT

SiLU

Right Ventricular Outflow Tract

Sigmoid Linear Unit

右室流出道切面

Sigmoid 激活函数

空间金字塔池化

层

SPP

Spatial Pyramid Pooling

超声住院医师规

范化培训

STFR

STOUS

Standardized Training for Residents

Specialized Training in Obstetric Ultrasound

产科超声专科培

训

SURF

SVC

SVM

T

Speeded up Robust Features

Superior Vena Cava

Support Vector Machines

Trachea

加速稳定特征

上腔静脉

支持向量机

气管

TN

True Negative

真阴性

TP

True Positive

真阳性

VSD

3VT

3VV

Ventricular Septal Defect

Three Vessel Trachea View

Three Vessel View

室间隔缺损

三血管气管切面

三血管导管切面

42

福建医科大学硕士学位论文

综述

医学人工智能在产前超声方面的研究进展

摘要

产前超声是重要的产前筛查手段，产前超声的畸形检出率手段多种因素的影

响，如何减少甚至消除这些影响,提高产前超声的畸形检出率成为一大考验。医

学人工智能的发展让人们看到新的方向及方法，本文旨在阐述医学人工智能在产

前超声方面的主要研究方法及进展，旨在为医师研究产前超声的人工智能应用提

供思路和参考价值。

关键词：胎儿，产前超声，人工智能

Progress in medical artificial intelligence in prenatal ultrasound

Abstract：Prenatal ultrasound is an important means of prenatal screening. The

detection rate of malformations by prenatal ultrasound is affected by many factors.

How to reduce or even eliminate these effects and improve the detection rate of

malformations by prenatal ultrasound has become a big test. The development of

medical AI makes people see new directions and methods. This paper aims to describe

the main research methods and progress of medical AI in prenatal ultrasound, and

provide ideas and reference value for doctors to study the application of AI in prenatal

ultrasound.

Key words: fetus, prenatal ultrasound, artificial intelligence

产前超声作为产前诊断技术之一，以其便捷、廉价、无辐射等优势在胎儿结

构畸形诊断中起着重要作用[1]。产前超声可用于胎儿各解剖结构关系的观察与评

估，以筛查常见的先天性畸形，例如无脑儿、单心室、开放性脊柱裂等[2-3]。但

是受胎儿因素（包括不自主运动、体位）、超声医师技术水平差异、仪器分辨率

及母体因素影响，获取高质量、标准的胎儿超声图像仍具很大挑战，胎儿先天性

异常检出率地区间差异明显[4]。如何缩短这种差距，成为一大困难和挑战。而随

着科技的发展，人工智能（Artificial Intelligence，AI）进入了人们的视线。如何

利用 AI 来提高原始图像质量，减少各种因素对检出率的影响成为了研究热点。

43

福建医科大学硕士学位论文

自 20 世纪 50 年代 AI 出现并发展至今，AI 已成为当代战略性核心技术领

域的标志[5]。AI 技术的到来，使医疗技术发生了颠覆性的变革，如：（1）AI 设

备阅片，在保证准确率的前提下，AI 设备阅片的效率是普通医生的几十倍甚至

更高，还能够帮助医生处理临床上一些复杂问题，用以减轻医师负担[6]；（2）

可穿戴设备监测健康记录，患者可通过所佩戴的设备随时了解自身状况；（3）

识别医生语音或笔记，AI 相应设备能够精确形成电子健康记录存储在病历数据

库中，无需花费人力再去整理；（4）陪护机器人的研究，陪伴机器人既能代替

医生去辐射高危地区，又能时刻陪护病人，做到随时感受病人健康数据与情绪波

动等[7]

。

AI 技术在医学的应用主要为以下几个方面：智能药物研发[8]、智能辅助诊疗

[9-10]、智能语音识别与语义理解[11]、健康管理和医院管理[12]。对于医学影像方面

而言，AI 技术主要体现在智能辅助诊疗[13-14]方面，医学影像的主要工作是识别各

类影像图片，而 AI 模型通过训练可“学习”不同图像的特征[15]，从而识别图像、

分类图像[16-17]。超声图像与 CT、MRI 图像不同，超声图像的获取易受多种因素

影像，它依赖于病人条件以及医师操作手法等[18]。超声医师审核与 AI 技术相结

合，可提高产前超声筛查的准确性，甚至发现肉眼可能无法检测到的额外预测信

息

[19]。因此，医学 AI 技术在超声诊断方面展示出良好的前景。

目前，AI 技术在超声图像识别方法主要分为传统目标检测算法和基于深度

学习的目标检测算法。本文将从这两种方法在胎儿产前超声图像识别的应用情况

进行综述，探讨 AI 技术在识别胎儿各解剖部位图像及产前诊断中的应用前景。

1 传统目标检测算法在产前超声的应用

传统目标检测方法是建立在手工制作特征和浅层可训练架构上的。主要分为

三个步骤:特征提取、特征编码和特征分类[20]。通过图像预处理，人为手动标注

感兴趣区域，利用特征提取算法进行特征提取，在通过特征融合等形成特征向量

编码特征，最后使用其他算法进行特征分类，实现图像识别。

1.1 传统目标检测算法在产前超声颅脑检查的应用

胎儿超声颅脑切面主要有经丘脑切面，经小脑切面等，是相对较早结合 AI

技术的切面，其结构相对清晰，不同颅脑切面获取方式较胎儿心脏等方便。Liu

等

[21]通过活动表达模型拟合并定位了颅脑的标准平面，并使用活动外观模型方法

44

福建医科大学硕士学位论文

找到了正确扫描平面所特有的具体结构。给定一张超声扫描图首先检测胎儿头

部。如果检测到头部，再根据估计的头部方向校正头部区域。第二步是检测头部

区域中心是否存在复合结构，如丘脑及大脑镰。由于该结构的外观和形状有大量

的变化，利用主动外观模型来完成结构拟合的任务。最终实现对颅脑切面的定位。

1.2 传统目标检测算法在产前超声颜面检查的应用

胎儿超声颜面切面主要有鼻唇冠状切面，正中矢状切面，双眼球切面等，虽

然颜面不同切面区别很大，但是获取标准切面仍然是一个很大的挑战。Wang X[22]

等使用局部二值模式(Local Binary Pattern，LBP)和定向梯度直方图(Histogram of

Oriented Gradient，HOG)提取图像的纹理特征，使用支持向量机（Support Vector

Machines，SVM）学习纹理特征构建胎儿颜面识别模型。LBP[23]是一种用于描述

图像局部纹理特征的算子，具有明显的旋转不变性和灰度不变性等优点。HOG

是计算机视觉和模式识别中常用的描述图像局部纹理的特征，其在人脸识别和目

标跟踪中的应用效果显著[24]。SVM 作为传统方法中分类效果最佳的分类器之一，

在目标识别，分类领域拥有着不可撼动的地位[25]。利用 LBP 与 HOG 的融合模型，

再使用 SVM 分类，最后实现了胎儿颜面超声平面的识别和分类。

1.3 传统目标检测算法在产前超声腹部检查的应用

胎儿腹部脏器多，需要关注的信息多样，如何更好的定位各标准切面及测量

切面是研究的重点。2013 年 Ni 等[26]利用临床解剖学的知识，提出了上腹部标准

平面的自动定位方案;采用径向模型描述腹部平面内关键解剖结构的位置关系，

实现标准平面定位。2014 年，Lei 等[27]提出将底层特征与多层 Fisher 向量特征编

码相结合，构建完整的图像特征，并辅以 SVM 分类器实现标准胎儿平面的定位。

2 基于深度学习的目标检测算法在产前超声的应用

深度学习被认为是一种学习方法，可以直接处理并自动学习从原始数据(例

如超声图像)中获得的抽象特征。它具有自动分析超声图像任务的潜力，如病变/

结节分类，器官分割和物体检测。

45

福建医科大学硕士学位论文

2.1 基于深度学习的目标检测算法在产前超声心脏检查的应

用

胎儿心脏小，毗邻结构多，不同的切面相似性大。周小雪等[28]人利用对抗网

络和卷积神经网络( Convolutional Neural Network，CNN)构建模型识别胎儿四腔

心,对抗网络是一种无监督生成对抗学习网络,它由生成器和识别器构成,通过学

习无标注视频帧的特征后再生成与收缩末期四腔心图像相似的图像,从而利用无

监督学习来提高收缩末期四腔心切面的识别准确率。

2.2 基于深度学习的目标检测算法在产前超声颅脑检查的应

用

Bo Zhan 等[29]通过对原始图像进行高斯滤波平滑处理，输入特征提取网络，

其次通过卷积神经网络提取图像的深层特征，并分别输入区域建议网络(Region

Proposal Network，RPN)和类预测网络(Class Prediction Network，CPN)。然后 CPN

将判断器官是否符合标准并预测类别，RPN 将借助特征金字塔网络定位必要器

官的位置。最后，两个网络将信息组合在一起并输出最终结果实现超声检查过程

中对胎儿颅脑图像的定位及图像质量的控制。

2.3 基于深度学习的目标检测算法在产前超声腹部检查的应

用

Deepika 等[30]提出了一种利用超声图像诊断胎儿异常的模型，利用 CNN 架

构与 U-Net 和 Houghman 变换方法的主要特征相结合，分割超声图像的主要部分。

其中 CNN 用于特征提取和分类，它降低了时间复杂度，提高了学习、特征提取

和分类的效率。一组图像输入模型中, 模型先自动学习并识别图像中的物体(胎

儿)，学习到的图像被标记为训练过程，它应用于网络中的整个数据。在学习阶

段，它将根据物体的外观、位置、像素值等来理解特征。每一层从前一层获取数

据，转换并传递给下一层。该网络根据从数据中学习到的内容逐层增加细节和复

杂性，以分层方式使用 CNN 架构来计算各种测量，最终用以确定胎儿的异常。

总结

AI 技术在超声医学方面的应用主要体现在辅助诊断上，AI 技术能够帮助超

声医师注意超声图像的微小细节，帮助超声医师评估疾病性质，减轻超声工作对

医师的负荷。但如何扩大超声数据，提高超声数据质量，提高诊断准确率，减少

误诊漏诊，是我们一直要努力的方向。现如今，AI 技术在产前超声中的发展仍

46

福建医科大学硕士学位论文

处于起步阶段，无论是传统目标检测算法还是基于深度学习的目标检测算法，在

产前超声方面的研究都较少，可见 AI 技术与产前超声的融合具有巨大发展前景，

希望有越来越来多的研究者投入其中，致力于 AI 技术研究服务于医学。

47

福建医科大学硕士学位论文

参考文献

[1]王凤兰,王建华,张云亭,等.胎儿结构畸形产前超声诊断分析[J].中华医学超声杂

志:电子版,2015,12(6):7.

[2]罗德清,陈欣林,朱霞,等.产前超声和 MRI 在诊断胎儿畸形中的应用[J].中国医

学影像技术,2016,032(004):586-590.

[3]闫景彬, 闫秀梅, 杨建享,等.产前超声筛查胎儿先天性心脏病的临床意义及高

危因素分析[J].中华全科医学, 2016, 14(1):114-115,160.

[4]American Institute of Ultrasound in Medicine. AIUM practiceguideline for the

performance

of

obstetric

ultrasound

examinations[J].Ultrasound

Med,2013,32(6):1083-1101.

[5]泮思林,罗刚.医学人工智能在胎儿超声心动图中的应用前景[J].中国实用儿科

杂志, 2020, 35(11):4.

[6]Basarab A,Liebgott H,Morestin F,et al.A method for vector displacement

estimation with ultrasound images and its application for thyroid nodular

disease[J].Medical Image Analysis,2008,12(3):259-274.

[7]巩高, 黄文华, 曹石,等.人工智能在医学的应用研究进展[J].中国医学物理学杂

志, 2021,38(8):1044-1047.

[8] Zoltán D,Ceccarelli M.Machine learning prediction of oncology drug targets based

on protein and network properties[J].BMC Bioinformatics, 2020,21(104):1-12.

[9]叶冯颖,李尚青,苏淇琛,等.计算机辅助诊断系统基于不同指南诊断甲状腺良恶

性结节的对比分析[J].临床超声医学杂志, 2020, 22(9):694-696.

[10]叶冯颖,杨文敏,李尚青,等.计算机辅助诊断软件联合多学科建立甲状腺结节

恶性风险预测模型[J].中国医学物理学杂志, 2021,38(1):54-60.

[11]刘一彤.人工智能在医疗领域的应用[J].科技传播, 2019,11(7):163-165.

[12]赵杰,蔡艳岭,孙东旭,等.远程医疗的发展现状与未来趋势[J].中国卫生事业管

理,2014,31(10):739-740,799．

[13]高思琦,牛司华, 黄剑华,等.超声人工智能在乳腺良恶性疾病鉴别诊断中的应

用[J].中国超声医学杂志, 2021,37(7):752-755.

[14]王丹,李程,孙静改,等.超声人工智能诊断系统联合远程医疗的临床价值探讨

[J].中国超声医学杂志, 2021,37(7):765-766.

[15]Cheng HD,Shan J,Wen J,et al.Automated breast cancer detection and

classification using ultrasound images: A survey[J].Pattern Recognition,2010,

43(1):299-317.

48

福建医科大学硕士学位论文

[16]Perez JE,Waggoner AD,Barzilai B,et al.On-line assessment of ventricular

function by automatic boundary detection and ultrasonic backscatter imaging[J].

Am Coll Cardiol,1992,19(2):313-320.

[17]Fatima M,Pasha M.Survey of machine learning algorithms for disease

diagnostic[J].Intet Learn Sys Appl,2017,9(1):1-16.

[18]H Chen,D Ni,J Qin,et al.Standard plane localization in fetal ultrasound via

domain transferred deep neural networks[J].Biomedical and Health

Informatics,2015,19(5):1627-1636.

[19]Madani A,Arnaout R,Mofrad M,et al.Fast and accurate view classification of

echocardiograms using deep learning[J].NPJ Digit Med,2018,1:6.

[20]X Zhu,H I Suk,L Wang,et al.A novel relational regularization feature selection

method for joint regression and classification in AD diagnosis[J].Medical Image

Analysis,2017,(38):205–214.

[21]Liu X,Annangi P,Gupta M,et al.Learning-based scan plane identification from

fetal head ultrasound images[J].Proceedings of SPIE - The International Society

for Optical Engineering, 2012, 8320:9.

[22]Wang X,Liu Z,Du Y,et al. Recognition of fetal facial ultrasound standard plane

based on texture feature fusion.[J].Computational and Mathematical Methods in

Medicine, 2021(6):1-12.

[23]Ojala T,Pietikainen M,Harwood D.A Comparative study of texture measures with

classification based on feature distributions[J].Pattern Recognition,1996,

29(1):51-59.

[24]Dalal N,Triggs B.Histograms of oriented gradients for human detection[C]// 2005

IEEE Computer Society Conference on Computer Vision and Pattern

Recognition (CVPR'05), 2005,1: 886-893.

[25]Joachims T.Making large-scale SVM learning practical[J].Technical Reports,

1998,8(3):499-526.

[26]Dong N,Li T,Xin Y,et al. Selective search and sequential detection for standard

plane localization in ultrasound[C]// Abdominal Imaging 2013. Springer, Berlin,

Heidelberg, 2013:203-211.

[27]Lei B,Zhuo L,Chen S,et al.Automatic recognition of fetal standard plane in

ultrasound image [C]//2014 IEEE 11th International Symposium on Biomedical

Imaging (ISBI),2014: 85-88.

[28]周小雪,张莹莹,张烨,等.人工智能技术在胎儿超声心动图四腔心切面筛查中

的应用[J].中华超声影像学杂志, 2020, 29(8):5.

49

福建医科大学硕士学位论文

[29]Zhang B,Liu H,Luo H,et al.Automatic quality assessment for 2D fetal

sonographic standard plane based on multitask learning[J].Medicine,

2021,100(4):e24427.

[30]Deepika P,Suresh R M,Pabitha P.Defending against child death: Deep

learning‐based diagnosis method for abnormal identification of fetus ultrasound

Images[J].Computational Intelligence, 2020,37(1):128-154.

50


## 图片

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img1.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img1.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img2.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img2.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img3.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img3.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img4.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img4.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img5.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img5.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img6.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img6.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img7.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img7.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img8.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img8.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img9.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img9.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img10.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img10.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img11.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img11.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img12.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img12.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img13.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img13.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img14.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img14.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img15.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img15.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img16.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img16.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img17.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img17.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img18.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img18.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img19.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img19.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img20.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img20.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img21.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img21.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img22.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img22.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img23.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img23.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img24.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img24.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img25.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img25.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img26.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img26.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img27.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img27.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img28.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img28.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img29.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img29.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img30.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img30.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img31.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img31.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img32.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img32.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img33.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img33.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img34.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img34.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img35.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img35.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img36.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img36.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img37.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img37.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img38.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img38.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img39.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img39.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img40.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img40.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img41.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img41.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img42.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img42.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img43.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img43.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img44.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img44.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img45.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img45.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img46.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img46.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img47.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img47.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img48.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img48.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img49.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img49.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img50.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img50.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img51.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img51.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img52.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img52.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img53.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img53.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img54.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img54.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img55.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img55.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img56.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img56.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img57.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img57.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img58.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img58.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img59.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img59.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img60.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img60.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img61.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img61.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img62.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img62.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img63.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img63.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img64.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img64.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img65.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img65.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img66.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img66.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img67.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img67.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img68.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img68.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img69.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img69.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img70.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img70.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img71.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img71.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img72.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img72.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img73.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img73.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img74.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img74.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img75.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img75.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img76.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img76.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img77.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img77.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img78.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img78.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img79.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img79.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img80.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img80.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img81.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img81.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img82.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img82.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img83.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img83.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img84.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img84.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img85.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img85.jpeg)

![人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img86.jpeg](images/人工智能自动识别胎儿心脏超声标准切面的研究_吴慧玲(2)_img86.jpeg)

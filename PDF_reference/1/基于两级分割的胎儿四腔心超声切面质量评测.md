## Page 1

2476
E-mail：jig@aircas．ac．Cll
Website：www．cjig．01q
"rel：01 0—58887035
中国图象图形学报
JOURNAL OF IMAGE AN0 GRAPHlOS
◎中国图象图形学报版权所有
中图法分类号：TP391．4
文献标识码：A
文章编号：1006．8961(2023)08．2476．15
论文引用格式：Xu G z，Qian Y F，Wang Y，Liu R，Zhou J and Lei B J，2023，Quatty assessment for letal f01lr—chamher uhrasound views based on
two-stage segmentation．Journal ofImage andGraphics，28(08)：2476—2490(徐光柱，钱奕凡，王阳，刘蓉，周军，雷帮军．2023．基于两级分割的
llJl—l!lll心超声切面质量评测．中国图象图形学报，28(08)：2476-2490)[DOI：10．11834／jig．220347]
基于两级分割的llJL四腔心超声切面质量评测
徐光柱1’2，钱奕凡1’2，王阳3，刘蓉3，周军3，雷帮军L2+
1．湖北省水电工程智能视觉监测重点实验室(三峡大学)，宜昌443002；2．三峡大学计算机与信息学院，宜昌443002
3．宜昌市中心人民医院超声科，宜昌443003
摘要：目的为解决基于深度学习算法在执行胎儿四腔心超声切面图像质量评测时无法准确反映心脏区域中瓣
膜与房室间隔及心室心房区域的可见程度问题，提出一种目标检测与两级分割相结合的胎儿四腔心超声切面图像
质量评测方法。方法首先利用自行构建的胎儿超声切面数据集-ll【练主流的YOLOv5x(you only look
onee v5x)模
型，实现四腔心区域与胸腔区域的有效定位。当检测到四腔心区域在胸腔区域内时，将其视为感兴趣区域送人训练
好的U2．Net模型，进一步分割出包含心房室及瓣膜的部分。然后利用形态学算子去除其外围可能存在的少许心
脏外膜区域得到四腔心内区域后，通过直方图修正与最大类间方差法(OTSU)相结合的方法分割出瓣膜连同房室
问隔区域，并通过减法操作得到心室心房区域的分割图。最后通过联合lfiJL四腔心超声切面图像中瓣膜连同房
室间隔与心室心房区域的面积之比、瓣膜与房室间隔区域以及心室心房区域的平均灰度构建评分公式与评分标准，
实现胎儿四腔心超声切面图像质量的有效评测。结果在胸腔和四腔心区域的检测任务上的mAP@0．5、mAP@
0．5-0．95和召回率分别为99．5％、84．6％和99．9％；在四腔心内部区域分割任务上的灵敏度、特异度和准确度分别
为95．O％、95．1％和94．9％；所提质量评测方法在所构建的A、B、C三类评测数据集上分别取得了93．7％、90．3％和
99．1％的准确率。结论所提方法的评测结果与医生主观评测结果相近，具有较好的可解释性，拥有良好的实际应
用价值。
关键词：深度学习(DL)；卷积神经网络(CNN)；超声图像质量评测；目标检测；两级图像分割
Quality assessment for fetal four-chamber ultrasound views
based on two-stage segmentation
Xu Guangzhul一，Qian Yifanl一，Wang Yan93，Liu Ron93，Zhou Jun3，Lei Bangjunl’2+
』．Hubei Key Laboratory ofIntelligent Vbion Based Monhonngyor Hydroelectric Engineering，China Three Gorges University
Yiehang
443002，China；2．College ofComputer and Information Technology，China Three Gorges University，
Y七hang
443002，China；3．Ultrasound Department，Yichang Central People’s Hospital，Ywhang
443003，China
Abstract：0bjecfive To diagnose the fetal congenital heart disease(CHD)during screening，clinical—related ultrasound
technique
is adopted and focused on the captured images in terms of different critical cardiac scanning planes．Ultrasound
scanning image quality assessment(QA)is indispensable for its efficiency and effectiveness．Four—chamber(4C)view—
related multiple fetal cardiac ultrasound
scan planes are commonly—used for CHD．The emerging artificial intelligence(AI)
technique
is beneficial for automatic fetal 4C view QA algorithm research further．In recent),ears，deep convolutional neu—
ral network(DCNN)based AI technique has been widely developing in the context of medical image processing and analy一
收稿日期：2022．04—19；修回日期：2022—07—08；预印本日期：2022—07．15
{通信作者：雷帮军bangjun．1ei@ieee．org
万方数据



### 图片

![基于两级分割的胎儿四腔心超声切面质量评测_page1_img1.png](images/基于两级分割的胎儿四腔心超声切面质量评测_page1_img1.png)

## Page 2

徐光柱，钱奕凡。王阳，刘蓉，周军，雷帮军
第28卷／第8期／2023年8月
基于两级分割的胎儿四腔心超声切面质量评测
sis．However，duo
to
the lack of relevant data—sets and
the 4C region only occupying
a small part in the whole fetal 4C
view，the confidence of detection bounding—box from general
purpose object detection network is chalenged
to reflect the
visibilitv and
clarity of four chambers
of the heart and
its related crux
area well，which includes mitral valve，tricuspid
valve，interatrial septum and interventricular septum in cardiac region．In addition，current fetal 4C view QA methods are
still challenged for reasonable explainability based
on pure deep learning(DL)techniques．To resolve
this problem，we
proposed a novel fetal 4C
view QA algorithm through the integration of object detection arid two‘‘stage segmentation opera—
tions，which is mutual—benefited for both of DL and traditional image processing techniques to get better accuracy and inter-
pretability．Method A self-built medical data—set of
1 696 images
is used for fetal 4c view QA research．The data-set offers
common objects
in context(COCO)format labels
for 4C and thorax regions，semantic segmentation labels for 4C
inner
regions，and
also contains QA labels annotated manually．First，object detection network
of you
only look
once v5x
(YOLOv5x)is trained
to realize effective 4C region detection and extraction．It illustrates
that the 4C region’s location
is
normal and can be treated as the region of interest(ROI)when the detected 4C region locates inner the thorax region．And
the R01 will be fed into the semantic segmentation network U2．Net which is well trained based the 4C inner region
data—set
which is a sub—set of the self-built data—set．The U2_Net considers four chambers of the heart and
crux
areas as foreground
and implements the initial segmentation．And，the U2一Net output is a gray—scale image，in which values of background
pix—
els are restrained effectively and foreground pixels
are highlighted as well．Then，the maximum inter-class
variance method
(OTSU’s method)is adopted
to binarize the
U2-Net output．Tile morphological erosion operation
is employed
to optimize
the binary segmentation result further，and a binary mask
is produced
to isolate the gray—scale 4C region．Next，0，11SU-
integrated histogram adjustment is used
to separate the
crux area leveraged from the isolated 4C rcgion．And，the
rest part
of it can be considered as the four chambers of the heart area．After that，three QA indices are designed，and they can be
used
to represent area ration of the crux and four chambers of the heart，average gray scale of the
crux and four chambers of
the heart．Finally，to achieve effective fetal 4C view QA，evaluation formulations and standards are developed based on the
three QA indices above．Result The experimental results show that the well trained YOL0v5x model based
on the self-buih
data—set can achieve 99．5％mAP@0．5 and 84．6％mAP@0．5-0．95 in the object detection task for thorax and 4C regions
respectively，and the recall rate
is
as high
as 99．9％；and the
well trained U2-Net model
can achieve
95．O％sensitivity，
95．1％specificity and 94．9％accuracy in
the
segmentation
task for 4C
inner region．The proposed
fetal 4C view QA
method can get 93．7％，90．3％and 99．1％accuracy on each evaluation data—set of class A。B and C．Conclusion To solve
the problem that DL based image classification network cannot consider the location relationships of anatomy parts，and the
objeet detection network cannot
reflect their visibility and clarity，which leads to unreliable evaluation results，a fetal 4C
view QA algorithm
is proposed based on an object detection incorporated with two—stage segmentation．Evaluation resuhs
S]IOW that the trained object detection network has
its potentials for 4C and thorax region detection，and the a'ained sere821．
tic segmentation network
is optimized for 4C inner region extraction
as well．The adopted two—stage segmentation strategy
which combines DL and traditional image processing
can not only shrink the costs
of data annotation and network training
greatly，but also strengthen optimal explainable results
as well．The designed QA standards can be developed farther in
terms of the three key indices．
Key words：deep learning(DL)；convolutional neural network(CNN)；ultrasound image quality assessment：object
detection；two—stage image segmentation
0
引
言
胎儿先天性心脏病(简称先心病)是一种常见的
严重先天性畸形疾病，全世界每年大约有30万llJl．
死于先心病(Vullings，2019)。因此，产前排查是有
效预防胎儿出生缺陷的重要手段(Yagel等，2001)。
超声成像技术因其快捷方便无辐射等优点，广泛用
于产前筛查(Wang等，2021)。但不同于CT(aom—
puted tomography)和MRI(magnetic resonance imag．
ing)等医学影像，超声成像过程中常会引人多种噪
声，使用探头扫查的过程中又易受到胎儿活动的影
响，另外超声医师操作技术水平参差不齐且在判读
过程中存在主观差异，导致目前胎儿先心病检出率
万方数据



### 图片

![基于两级分割的胎儿四腔心超声切面质量评测_page2_img1.png](images/基于两级分割的胎儿四腔心超声切面质量评测_page2_img1.png)

## Page 3

较低。为了能够有效降低主观差异及图像获取质量
对胎儿先心病排查带来的影响，超声图像质量评测
已经成为产前超声诊断中必不可少的一个环节
(Dudley和Chapman，2002；Salomon和Ville，2005；
Rahmatullah等，201 1)，其评测过程通常由超声医生
手动完成，需要耗费医生大量的时间和精力(Salo．
mOB等，2006)。在产前筛查过程中，超声医生通常
会采集多个重要的心脏切面图像，其中，四腔心
(four．chamber，4C)切面是胎儿心脏超声图像中最重
要的切面，也是最早用于诊断胎儿先心病的切面
(Lange等，1980；Del Bianco等，2006；Jeanty等，
2007)：因此，开展胎儿四腔心超声切面图像自动质
量评测算法研究不仅可以减轻超声医生的工作负
担，而且对拓展其他超声切面的自动质量评测也具
有一定的参考价值。
医学超声虽具多种优势，但因受自身成像原理
限制，所成影像往往分辨率不高且噪声污染严重，致
使单纯采用传统图像处理与机器学习算法的辅助诊
断准确率偏低(武玉多等，2021)。近年来，基于深
层卷积神经网络的深度学习技术，因其能够基于大
规模图像数据集自动学习。适用于上游多种应用的
鲁棒性图像特征，在医学图像处理与分析领域取得
了突破性进展。越来越多的研究开始尝试深度学习
在胎儿超声图像处理中的应用，但有关胎儿超声图
像质量评测的研究还较少。Abdi等人(2017)利用
i级卷积层配合池化操作并串接两个全连接层对成
人心尖朝上的四腔心切面图像质量得分进行了回归
式预测，将0～5的预测得分值划分为6类质量等级：
虽然所训练的回归网络能对输入图像进行总体评
分，但其不适用于胎儿四腔心超声切面质量评测，一
方面是因为其所用切面为四腔心局部区域，类似于
图1(a)中的检测框所示；另一方面，从该网络所学
到的特征可视化结果能够发现，最终的评分结果很
大程度上是受到心脏外侧边缘的影响，不能很好地
对四腔心区域内部解剖部件的可见程度给出稳定、
可靠且准确的评分。为了能够在产前排查中快速检
测13个标准切面(其中包含4个心脏区域的切面)，
Baumgartner等人(2017)设计了SonoNet(sonography
network)。在排查切面类型的同时，通过利用计算网
络反向传播过程中的梯度值，反演出输入图像中感兴
趣区域像素对网络输出结果的影响，进而实现不同切
面中对应解剖部件的准确定位。虽然SonoNet能够检
测多个切面及完成部件定位，并通过检测到的解剖
部件数量得到对应切面的质量分数，但对于四腔心
区域只能给出整体的定位，未能对内部部件的可见
程度进行更加详细的评测。然而，这种基于解剖部
件数量的评分思路启发了后续其他科研工作者。
网1
不同可见程度的四腔心区域检测结果示例
Fig．1
Detection result instances of^)ul-chamber(4C)
regions with different clarity degrees
((a)non—standard 4C region：(h)standard 4C region)
Lin等人(2018)利用目标检测网络Faster
R-CNN(faster region-based
eonvolutional
neural
net—
work)(Ren等，2017)对胎儿头部超声图像中的组织
进行直接定位，并通过统计定位到的解剖部件数量
得到对应切面的质量分数。与胎儿心脏区域不同，
头内部区域中各组织的超声成像相对固定且清晰，
而四腔心超声切面图像在获取过程中因心跳而变化
剧烈，对检测与分割都带来了挑战。因此，更多科研
工作者尝试采用多种网络协同检测。wu等人
(2017)利用两个不同的深度卷积神经网络分别对胎
儿腹部超声切面图像进行感兴趣区域(regions of
interest，ROI)定位及相关解剖部件检测，并根据是
否定位到ROI及所检测到的解剖部件的数量给出相
应切面的得分。Zhang等人(2021a)利用3个不同的
卷积神经网络分别对胎儿四腔心超声切面图像进行
特征提取、关键解剖部件的定位及类别预测，根据检
测到的解剖部件(如左、右心室心房)数量来对四腔
心切面图像评分。Lin等人(2018)、Wu等人(2017)
和Zhang等人(202la)的T作共同之处都是根据网
络模型检测到的解剖部件数量来得到相应切面图像
的质量分数。但由于在网络训练时采用的解剖部件
标签无法体现其可见程度的高低．因此仅基于解剖
部件数量无法有效衡量胎儿超声切面图像的质量。
为了能够给出图像本身的质量评测，Dong等人
(2020)利用3个不同的卷积神经网络将胎儿四腔心
万方数据



### 图片

![基于两级分割的胎儿四腔心超声切面质量评测_page3_img1.jpeg](images/基于两级分割的胎儿四腔心超声切面质量评测_page3_img1.jpeg)

## Page 4

第28卷／第8期／2023年8月
徐光柱．钱奕凡．王阳，刘蓉，周军，雷帮军
基于两级分割的胎儿四腔心超声切面质量评测
超声切面图像的质量评测分解成3个阶段，分别是
提取四腔心切面图像、判定切面图像的增益强度和
缩放比例以及检测切面图像上的解剖部件，最后根
据解剖部件数量及图像增益和缩放程度得到切面图
像的质量分数。该方法不仅依据网络模型检测到的
解剖部件数量来对切面图像质量进行评分，而且考
虑了切面图像整体质量p司素(如增益和缩放比例)。
这种方法通过将切面图像整体清晰程度与局部解剖
部件存在与否相结合．能在一定程度上间接实现解
剖部件的可见性评测。但因四腔心区域在整个切面
中所占比例较小，切面图像的整体增益与缩放比例
这两个指标很难有效体现四腔心区域中心脏瓣膜以
及心室心房的可见度，从而无法判断当前获得的切
面是否为最佳观察时期的图像二
虽然上述多种算法在胎儿四腔心超声切面图像
质量评测任务上取得了一定进展，但该问题的解决
仍然存在多种网难与挑战。具体如下：1)由于构建
医学图像数据集通常需要一定的医学专业知识，而
构建基于深度学习的医学图像数据集更是耗时耗
力，目前尚未发现公开可用于胎儿四腔心超声切面
图像质量评测的数据集。2)由于缺乏大规模适用于
胎儿四腔心区域检测的超声数据集，在实际应用中
目标检测模型的检测框置信度往往难以反映四腔心
区域的可见程度(如图l所示)，因此需要借助其他
辅助手段来对胎儿四腔心超声切面图像进行质量评
测。3)缺乏统一、有效且可解释的胎儿四腔心超声切
面图像质量评测方法和规则(Zhang等，2021b)。4)
目前针对胎儿四腔心超声切面图像质量评测的方法
大多都是基于纯深度学习的，结果的可解释性不强。
针对上述问题，本文采用合作单位临床数据，构
建了一个包含1 696幅图像的胎儿四腔心超声切面
图像质量评测数据集，并在此基础上将深度学习技
术与传统的图像处理算法相结合，提出了一种能够
实现四腔心区域准确定位及其内部区域解剖部件有
效分割的方法：同时，利用各解剖部件的面积之比
及平均灰度，设计了一种与直观感受一致且具有较
好可解释性的评分标准，实现对胎儿四腔心超声切
面图像质量的有效评测。
1相关技术
1．1单阶段目标检测模型YOLOv5x
YOLOv5(you
only
look
once
v5)(Uhralytics．
2020)是YOLO系列(Redmon等，2016；Redmon和
Farhadi，2017，2018；Bochkovskiy等，2020)中使用较
为广泛的一种目标检测网络，它能够兼顾目标检测
的速度与精度。该网络主要南骨干、颈部及预测端
即头部组成。YOLOv5网络通过在训练时引入马赛
克(mosaic)数据增广、自适应的锚框计算及图像缩
放策略，在骨干部分中将Focus下采样技术与跨阶
段局部网络(cross stage
partial network，CSP)相结
合，增强了网络的特征融合能力，实现了检测性能的
进一步提升。YOLOv5目前有YOLOv5s、YOLOv5m、
YOLOv51和YOLOv5x共4种不同规模的网络结构，
相比前3种，YOLOv5x拥有更大的网络深度与网络
宽度(如图2所示)，具有更好的特征提取与融合性
能：冈此，本文采用这种模型定位胎儿超声图像中
的四腔心及胸腔区域，所用训练参数如表1所示。
冈2
Y()I。()v5x『叫络2。‘i构』刳
¨lg．2‘l'ht-sh’tl(-ttu’t·llI-YOI．()、5x nPl、~OI‘k
2479
万方数据



### 图片

![基于两级分割的胎儿四腔心超声切面质量评测_page4_img1.jpeg](images/基于两级分割的胎儿四腔心超声切面质量评测_page4_img1.jpeg)

## Page 5

中国图象图形学报
JOURNAL OF lMAGE AND GRAPHICS
表1
YOLOv5ijiI练参数
Table 1
Training parameters of YOLOv5
参数
数值
输入尺寸／像素
学习率
动量
权重衰减
640 X 640
0．002 5
0．9
0．000
1
1．2语义图像分割模型U2-Net
U2_Net(Qin等，2020)是一种u型对称结构的全
卷积神经网络，具有良好的语义分割性能，主要由
6级编码器(En-l—En一6)和5级解码器(De_l—De一5)
以及显著图融合模块组成，如图3所示。其采用的
新型残差结构(residual U。blocks，RSU)能够融合不
同尺寸的感受野特征，从而捕获更多尺度的上下文
信息，相比于在医学图像分割领域广泛使用的
U．Net(Ronneberger等，2015)网络而言，具有更强的
图像语义分割能力：因此，本文采用这种网络模型
实现四腔心内部区域的初级分割，网络所用训练参
数如表2所示。
表2
U2一Net训练参数
Table 2
Training parameters of U2_Net
参数
数值
输入尺寸／像素
学习率
一阶矩估计衰减系数
二阶矩估计衰减系数
2胎儿四腔心切面图像质量评测方法
本文设计的结合目标检测与两级分割的胎儿四
腔心超声切面图像质量评测方法，主要包括4个步
骤：1)将图像输入到训练好的YOLOv5x目标检测模
型中，实现对四腔心区域的定位与提取；2)将提取的
四腔心区域图像输入到训练好的U2-Net分割模型
中，将心室心房、瓣膜与房室间隔区域作为前景目标
进行语义分割；3)利用形态学处理、直方图修正与最
大类间方差法(OTSU)(Otsu，1979)相结合的方法，
从U2_Net的初级分割结果中进行二级分割，分别得
到瓣膜连同房室间隔区域和心室心房区域；4)根据
日口T皿邻
日U T叫日U
日胍慕蒜
日㈣黧要!}}{
日㈨曼
日爿P[psa篇mple：to
i“onpnu““‘
罔3
U 2_Net网络结构』皋I
¨lg．3
7Hie
sII．tlchlre of U 2_Net IlfttWOl’k
分割结果分别计算出瓣膜连同房室间隔区域与心室
心房区域的面积之比、瓣膜与房室间隔区域以及心室
心房区域的平均灰度，并将上述指标作为评价因子构
建评分公式。通过计算和比较质量分数的大小，得到
评测图像对应的评级，并根据预设的评测规则输出相
应的质量评测报告，整个算法流程如图4所示。
2．1
四腔心区域的定位与提取
胎儿四腔心超声切面图像主要南胸腔与四腔心
区域构成，评测其图像的质量高低，首先就是要实现
胸腔与四腔心区域的定位，根据胸腔与四腔心区域
的位置关系，判断该心脏区域位置是否出现异常。
当四腔心区域在胸腔区域内时，表明心脏位置正常，
可将算法检测到的四腔心区域提取⋯来做进一步分
析。由于YOLOv5x模型同时具有较高的检测精度
和较快的检测速度，本文选取YOLOv5x模型来定位
胸腔与四腔心区域，并根据两者的位置关系提取四
腔心区域，如图5所示。其中红色小框表示四腔心
区域，绿色大框表示胸腔区域：
2．2
四腔心区域解剖部件的分割与提取
四腔心区域主要包含瓣膜与房室间隔、心室心
房两类重要解剖部件。由于YOLOv5x目标检测模
型只能对解剖部件的整体区域进行定位。无法准确
提取出具体的解剖部件(如瓣膜与房室间隔)，且检
测框置信度无法准确反映该区域内解剖部件的可见
程度(如图1所示)，冈此需要通过进一步的图像分
2
蛾
叫
均
哟
狲
∞
n
∞
3
万方数据



### 图片

![基于两级分割的胎儿四腔心超声切面质量评测_page5_img1.jpeg](images/基于两级分割的胎儿四腔心超声切面质量评测_page5_img1.jpeg)

## Page 6

第28卷／第8期／2023年8月
徐光柱，钱奕凡，王阳，刘蓉。周军，雷帮军
基于两级分割的胎儿四腔心超声切面质量评测
图4质量评测流程
Fig．4
The process of quality assessment
析方法来进行辨识。为了能够对评测结果给出较好
的解释，本文先采用U2．Net模型分割出四腔心内部
区域，通过掩膜操作屏蔽解剖部件外的区域，再利用
直方图修正与OTSU相结合的方法分割出瓣膜连同
房室间隔区域以及心室心房区域。接着，将灰度化
的四腔心区域图像分别与心室心房区域、瓣膜连同
房室间隔区域的分割图做掩膜操作，从而提取该四
腔心区域图像中的解剖部件。最后，根据解剖部件
的面积之比与平均灰度对该四腔心切面图像进行可
解释的质量评测。
2．2．1基于UZ-Net的四腔心内部区域分割
在提取四腔心区域的基础上，本文利用U2-Net
万方数据



### 图片

![基于两级分割的胎儿四腔心超声切面质量评测_page6_img1.png](images/基于两级分割的胎儿四腔心超声切面质量评测_page6_img1.png)

## Page 7

图5
pU腔心IxI域定他‘j提取过程
Fig．5
The ptl()(’ess of 4C regiml detection and extrat‘lion
((a)the detection of’4C region：(h)the extraction of4C region)
模型将心室心房区域和瓣膜连同房室间隔区域共同
视为前景目标分割⋯来，如图6所示?陶6(h)中白
色区域表示前景，黑色区域表示背景。此分割方法
所用的标签较容易标注，仅需标注前景和背景两类。
若使用多目标语义分割技术来分割四腔心区域中的
解剖部件，则需要按照瓣膜连同房室问隔区域、心室
心房I)(域的边缘进行标注，其数据集标注难度较大，
且模型训练成本较高。
曩箬口
口口口口
口口口口
(c)J掰付!操作Ji的分青1结粜
冈7
U二一Net输m结果的后处理示例
Fig．7
Some instant·Ps of U 2．Net outputs post—pt’ocessing
((a)U-'-Net output images：(h)binarizalion results of U2_Net
output images：(c)segmentation resuhs after erosion operation)
度化四腔心区域图像进行掩膜操作，以尽可能屏蔽
四腔心区域图像的背景，如图8(1，)(C)所示，接着，
进行四腔心区域内部解剖部件的精细分割。南
图8(C)可以看出，四腔心区域内部主要包含亮度较
大的瓣膜与房室间隔区域(可视为前景目标)和亮度
较暗的心室心房区域(可视为背景)?
{c)J离{小hj}≠j』拖l其操f1二{‘}至【m0I割像
周8
四腔心内部IxI域的后处理示例
Fig．8
Some instam。Ps of 4C inner regions post·processing
((a)grayst。ale images of 4C region：
(IJ)inmges obtained by mask operation before erosion：
(t—images obtained
b。v mask operation after erosion)
瓣膜与房室问隔区域的分割结果如图9所示。
当四腔心I)(域图像的前景与背景亮度相差不大时，
直接使用OTSU算法不能有效分割flj瓣膜与房室间
万方数据



### 图片

![基于两级分割的胎儿四腔心超声切面质量评测_page7_img1.jpeg](images/基于两级分割的胎儿四腔心超声切面质量评测_page7_img1.jpeg)

## Page 8

第28卷／第8期／2023年8月
徐光柱．钱奕凡，王阳，刘蓉，周军。雷帮军
基于两级分割的胎儿四腔心超声切面质量评测
隔区域，如图9(a)所示：实验发现．当心室心房区
域较亮时，即使先采用掩膜操作屏蔽四腔心区域图
像的背景，再利用OTSU算法仍不能很好地分割出
瓣膜与房室间隔区域，如图9(b)所示，这是因为
OTSU算法在分割时有大量像素值为0的区域参与
运算，导致它不能找到一个合适的阈值来分割出瓣
膜与房室间隔区域。故本文将直方图修正(即不统
欠度值
(c)r[方【gl修J{i』。j的分：#|J结粜
图9瓣膜与房室间隔区域的分割结果
Fig．9
Segmentation results of crux
areas
((a)segmentation results of using OTSU directly：
(b)segmentation resuhs of OTSU combining erosion and mask
operations：(‘。)segmentation results after histogram adjustment)
图10展示了图8(a)最右边罔的整个直方图修
正过程。将罔7(c)中经过腐蚀操作的U2_Net二值分
割图与图9(c·)中直方图修正与OTSU结合的分割结
果做减法操作，得到四腔心区域图像中心室心房区
域的分割图，如图11所示。
在整个测试集上的分割结果显示，上述做法能
够有效分割ffj瓣膜连同房室间隔区域和心室心房区
域，如图12所示，这里采用伪彩图的形式以便于更
清晰地看出分割结果。图12(a)表示提取的四腔心
区域图像，罔12(b)是其对应的分割结果，其中绿色
代表心室心房区域，红色代表瓣膜与房室间隔
区域。
2．3
四腔心超声切面图像的质量评测指标
四腔心区域作为胎儿四腔心超声切面图像中
800
700
600
羹|||
200
100
0
50
00
1)fJ
2(川2)0
火度fI：【
(c)修正后的旧腔心区域图像及对应的直方图
冈10直方冈修正过程
Fig．10
The adjustment process of histogram
((a)the grays(、ale image of 4C region and corresponding
histogram：(b)the image 01)tained by mask operation
after erosion and corresponding histugram；
(‘，)themodifiedimage of4C region and correspondinghistogram)
罔1 1
心室心房区域的分割结果
Fig．1
I
Segmentation rest,Its of fi)ur chambers of the heart
areas
最重要的部位，仅通过四腔心区域中左、右心室心
房的粗定位来评测四腔心切面是不够的。由于心
室心房区域是南瓣膜与房室间隔分隔而成的，因
此本文将瓣膜连同房室间隔与心室心房的面积之
比、瓣膜与房室间隔以及心室心房的平均灰度作
为评测一幅四腔心切面图像质量的3个重要指
标，并基于这些指标构建切面图像整体质量的评
分公式。
对于面积之比指标的计算，首先通过计算图7
攀
卜
。
像j强溜■
川撇
▲
万方数据



### 图片

![基于两级分割的胎儿四腔心超声切面质量评测_page8_img1.jpeg](images/基于两级分割的胎儿四腔心超声切面质量评测_page8_img1.jpeg)

## Page 9

圜
中国图象图形学报
30URNAL OF lMAGE AND GRAPHICS
(h)l儿¨j卞一C,l<t-,一{l J,l＆K J，fI￥爵|JiI：f‘f‘分：IH}占粜自0f句平；I§J
冈12
四腔心区域内部解剖部件的分割结果示例
Fig．12
Some segmentation result instances of anatomic
components
in 4C inner regions((a)4C region images：
(}))pseudo(、olor images of anatomic
components in 4C inner regions)
(c)中经过腐蚀操作的四腔心区域前景的像素点
个数与罔9(C)中瓣膜连同房室问隔区域的像素
点个数之差，得到心室心房区域像素点个数，然
后得到待评测的胎儿四腔心超声切面图像中瓣
膜连同房室间隔与心室心房区域的面积之比矗’，
具体为
∑∑日i
k’=———三尘兰——一
(1)
∑∑4。一∑∑曰．，
⋯Ij
i=¨=I
式中，A为经过腐蚀操作的U2_Net二值分割罔的像
素矩阵，曰代表直方图修正与OTSU结合分割m的瓣
膜与房室间隔区域图像像素矩阵：A，，与B。分别表
示对应像素矩阵中的元素÷
对于瓣膜与房室间隔区域的平均灰度指标的计
算，首先将图8(a)中灰度化的四腔心区域图像与
罔9(C)中直方冈修正与OTSU结合的分割结果进行
掩膜操作，提取四腔心区域图像中的瓣膜与房室问
隔区域，如同13所示：然后，计算瓣膜与房室间隔
IX域的平均灰度k“。具体为
∑∑(c．术剐。，
∥=生旦1——一
(2)
∑Y／_2曰Ⅱ
厶u q
式中，．*表示两个矩阵对应元素相乘(掩膜操作)，
C为灰度化的四腔心区域图像(图8(a))的像素
矩阵。
冈13经过掩膜操作后的瓣膜与房室间隔区域图像
Fig．1 3
Some images ofl crux areas after
mask uperation
对于心室心房区域的平均灰度指标的计算，与
上一个指标稍有不同。首先将图8(a)中灰度化的
四腔心区域图像与图11中心室心房区域的分割图
进行掩膜操作，提取四腔心区域图像中的心室心房
区域，如图14所示。然后，计算心室心房区域的平
均灰度∥，具体为
∑∑[(A一剐．：I=G]，，
∥=255一生旦生—————二
(3)
∑∑A。一∑∑B。
冈14经过掩膜操作后的心室心房区域图像
Fig．1 4
Some images of f()ur chambers of the
heart areas after nlask operation
对于一幅质量较高的胎儿四腔心超声切面图
像，其四腔心区域中心室心房区域的实际平均灰度
值不能高于瓣膜与房室间隔区域的平均灰度值，且
应尽可能较暗(小)。但为了在后续构建评分公式
时，能保证心室心房区域的实际平均灰度值越小，对
四腔心切面图像质量分数的贡献越大，本文在式(3)
中采用255减去心室心房区域的实际平均灰度值，
作为心室心房区域的平均灰度指标∥。k⋯越大，表
明心室心房区域越暗；k⋯越小，表明心室心房区域
越亮。
对于评测切面图像质量分数的计算，首先计算
归一化后的3个质量评测指标，分别是面积之比Kl、
平均灰度乜和K，，具体为
万方数据



### 图片

![基于两级分割的胎儿四腔心超声切面质量评测_page9_img1.jpeg](images/基于两级分割的胎儿四腔心超声切面质量评测_page9_img1.jpeg)

## Page 10

第28卷／第8期／2023年8月
徐光柱，钱奕凡，王阳，刘蓉，周军，雷帮军
基于两级分割的胎儿四腔心超声切面质量评测
耻芸惫
K：=罟—专}
(4)
七m“一Rmin
妒等鼍
然后，将这3个归一化后的质量评测指标进行
加权统计，得到评测切面图像的质量分数F，具体为
1 0．4K．+0．35K2+0．25K，0≤Kl<0．66
F={0．4K．+0．35E+0．25K，一
(5)
l K。一0．66)0．66≤K。≤1
式中，蜀，砭，K3“0，1]。
考虑到瓣膜连同房室间隔与心室心房的面积之
比不能过大，当归一化后的面积之比≥0．66时，应
当给以适当的分数惩罚。
统计标准的胎儿四腔心超声切面图像中瓣膜连
同房室间隔与心室心房区域的面积之比|j}’、瓣膜与
房室间隔区域以及心室心房区域的平均灰度k”和
k”’这3个质量评测指标所处的范围，分别是0．11～
0．57、44～143和189～248；当局’、k”和k⋯都在预先
设定的阈值范围内时，根据F的大小来判断该四腔
心切面图像的质量高低，同时参照预先设定的质量
评测规则，给出相应的质量评测报告；否则，将其归
为问题切面交由医生来进一步判断。为了降低不同
超声影像设备对所设计的评分等级划分标准的影
响，在做归一化时，本文根据数据集自身统计出了相
应的经验参数七：：I∽尼：。，碥。，矗：。，碟。，晟：，这种归
一化除了确保得出的分数处于O～1的范围内，还相
当于一种“校正”操作，以便于后续质量分级标准与
设备及数据集无关，在一定程度上提升了算法的鲁
棒性。预设的评测规则如下：
1)归一化后的面积之比K．。当0≤K。<0．31
时，表明瓣膜连同房室间隔与心室心房区域的面积
之比较小；当0．31≤K．<0．66时，表明瓣膜连同房
室间隔与心室心房区域的面积之比适中；当0．66≤
K．≤1时，表明瓣膜连同房室间隔与心室心房区域
的面积之比较大。
2)归一化后的平均灰度B。当0≤K2<0．25
时，表明瓣膜与房室间隔区域不清晰；当0．25≤
如<0．50时，表明瓣膜与房室间隔区域欠清晰；当
0．50≤K2≤1时，表明瓣膜与房室间隔区域清晰。
3)归一化后的平均灰度疋。当0≤K，<0．35
时，表明心室心房区域较亮；当0．35≤K，<0．70
时，表明心室心房区域亮度适中；当0．70≤K，≤1
时，表明心室心房区域较暗。
4)质量分数(得分)F。当0≤F<0．378时，评
级为C；当0．378≤F<0．473时，评级为B；当
0．473≤F≤0．864时，评级为A；由于当面积之比较
大时，会有一定的分数惩罚，因此质量分数最高不
超过1。
3实验结果与分析
3．1数据集与实验平台
目前，尚未发现公开可用于胎儿四腔心超声切
面图像质量评测的数据集。本文实验所用的数据来
源于宜昌市中心人民医院超声科，共收集了1 696幅
14～28周的胎儿四腔心超声切面图像，每幅图像由
超声科医生使用相同的超声设备(Voluson(荩)E10，
GE Heahhcare，Chicago，IL，USA)采集，如图5(a)
所示。数据集的构建步骤如下：1)标注数据集中的
四腔心区域和胸腔区域，构建YOLOv5x目标检测数
据集(胎儿四腔心超声切面图像)。2)根据已标注的
四腔心区域位置坐标将其提取出来，将四腔心区域
图像中心室心房、瓣膜与房室间隔区域(视为同一
类)作为前景，其他区域作为背景进行标注，构建
UZ-Net目标分割数据集(四腔心区域图像)，如图6所
示。3)按5：2：3的比例来划分YOLOv5x和U2-Net实
验所用的训练集、验证集和测试集，如图15所示。
质量评测实验所用的数据集来源于U2-Net的测试
集，如图16所示。实验所用软硬件环境如表3
所示。
3．2性能评估指标
在测试集上，本文采用召回率(recall)、平均精
度均值mean average precision，mAP)和帧率(frames
per second，FPS)对YOLOv5x模型在目标检测任务上
的性能进行评价，同时采用灵敏度(sensitivity，
SEN)、特异度(specificity，SPE)和准确度(accuracy，
ACC)对US-Net模型在分割任务上的性能进行评价。
mAP表示所有类别检测精确率的均值(葛青青等，
2021)。
3．3
四腔心超声切面图像质量评测结果分析
3．3．1
四腔心区域目标检测及内部区域分割结果
对于四腔心区域检测与内部区域分割任务，本
万方数据



### 图片

![基于两级分割的胎儿四腔心超声切面质量评测_page10_img1.png](images/基于两级分割的胎儿四腔心超声切面质量评测_page10_img1.png)

## Page 11

中国图象图形学报
JOURNAL OF IMAGE AND GRAPHICS
Vol
28，No
8．Aug 2023
(
外始)
』
原始数据集
胎JLIJq腔心超i
切ff【f图像
．——／j、＼．
YOLOv5 iJJ陈集YOL0v5测试集YOLOv5验证集
(50％)
(30％)
(20％)
j
j
j
U2一NetiJll练集
u二．Netig!JJ试集
u二．Net验证集
(50％)
(30％)
(20％)
j
质量}乎测测试集
(30％)
川腔心区域图f
j
(结束)
胎儿州腔心
超声切ll【f图像
叫腔心
区域图像
㈥15数据集划分流程
Fig．1 5
7Fhe diagram of data—sets division
文采用自己构建的目标检测及分割数据集分另tJiJll练
YOLOv5x和U2_Net模型，其在测试集上的表现如
表4和表5所示。同时，在MMDetection(open mmlal)
detection
toolbox)(Chen等，2019)和UNET．ZOO
(Zhu，2020)两个开源的检测和分割框架上，利用相
同的数据集来进行对比实验，实验结果见表4和
表5，其中mAP@0．5、mAP@0．5-0．95所用IOU阈值
与COCO数据集评测标准一致：可以看出，所训练
的YOLOv5x目标检测模型在四腔心区域和胸腔区
Ic)汁缎ZJ(、(Fj川IH：心Ix．如k㈣f壤
图16质量评测所j1J图像示例
Fig．1 6
Some inslances of the image set use(1 in quality assess—
ment((a)some instances l·ated
as class A：(I))some instances
rated as()lass B：((、)some instam、es rated as('lass C)
域检测任务上，mAP@0．5和mAP@0．5-0．95分别达
到99．5％和84．6％(最高)，且召回率为99．9％(最
高)，表明所训练的YOLOv5x模型在检测四腔心区
域和胸腔I哭域上具有较为优秀的检测性能；而所训
练的U2_Net目标分割模型相比主流的医学图像分
割模型，准确率达到了94．9％(最高)，灵敏度为
95．0％，特异度为95．1％。结果表明，所训练的U2一
Net模型在分割四腔心内部区域上具有较好的分割
性能?
表3软硬件环境
Table 3
The uesd environment of hardware and SOftware
表4检测模型在测试集上的性能表现
Table 4
The performances of detection model on the test set
注：加粗字体表示各列最优结果
万方数据



### 图片

![基于两级分割的胎儿四腔心超声切面质量评测_page11_img1.jpeg](images/基于两级分割的胎儿四腔心超声切面质量评测_page11_img1.jpeg)

## Page 12

徐光柱．钱奕凡，王阳，刘蓉，周军，雷帮军
第28卷／第8期／2023年8月
基于两级分割的胎儿四腔心超声切面质量评测
表5分割模型在测试集上的性能表现
Table 5
The performances of segmentation
model on the test set
注：加粗字体表示各列最优结果。
3．3．2
四腔心超声切面图像得分对比分析
南于四腔心超声切面图像质量控制更重要的是
要关注四腔心区域的可见程度，故本文通过其内部
解剖部件的面积之比、平均灰度来分析四腔心区域
的可见程度，并根据这块区域内解剖部件的质量得
到对应切面的质量评价。
根据本文所设计的质量评测规则．将所提出的
胎儿四腔心超声切面图像质量评测方法在测试集上
的评测结果与医生主观评测结果进行对比，结果如
表6所示。可以看出。C类的评测结果准确度最高，
原因是数据集中c类切面图像质量都较差，所对应
的四腔心区域可见度低，导致分割出的解剖部件面
积比及平均灰度得分偏低，相对易于判读。数据集
中A类和B类的切面图像相较C类而言，数量较多，
处在A、B两类阈值附近的图像易出现错分现象。虽
然本文提出的质量评测方法存在一定的错分情况，
但总体来说评测结果与医生主观评测结果相近。
表6质量评测方法在测试集上的性能表现
Table 6
The performances of quality assessment
method on the test set
评测结果
准确卒／％
．4
B
C
93．7
90．3
99．1
图17为四腔心区域的评测结果示例：根据预
设的质量评测规则，对测试集中四腔心切面图像的
部分评测结果如表7一表10所示。其中，K。表示归
一化后的面积之比，K表示归一化后的瓣膜连同房
室间隔区域的平均灰度，K表示归一化后的心室心
房区域的平均灰度。
c)鳙j，：’jk 7I-【、Ij．ili0
(d)弹法5引廷小i、Ii；l／!Jj
结粜邪乃A类
?}i粜1：·毁
图17
叫腔心区域的评测结果示例
Fig．1 7
Some evaluation instances for 4C region
((a)SOllle ins|[1llCeS of(·lass C：(h)S()llle ins|ances of(．1ass B；
(e)some iils Janees of class A：((I)some instances for
which Ihe algorithm gives(1ifterent judgemenls)
表7图17(a)的评测结果
Table 7
The assessment results of Fig．17(a)
从表7和陶17(a)可以看It；，图17(a)中l—4的面
积之比较小，瓣膜与房室问隔区域不清晰；图17(a)中
1的心室心房区域亮度适中，图17(a)中2—4的心室
心房区域较暗。
表8图17(b)的评测结果
Table 8
The assessment results of Fig．17(b)
万方数据



### 图片

![基于两级分割的胎儿四腔心超声切面质量评测_page12_img1.jpeg](images/基于两级分割的胎儿四腔心超声切面质量评测_page12_img1.jpeg)

## Page 13

中国图象图形学报
JOURNAL OF lMAGE AND GRAPHICS
从表8和图17(b)可以看出，图17(b)中1、3、4
的面积之比较小，而17(b)中2的面积之比适中；图
17(b)中1、3、4的瓣膜与房室间隔区域欠清晰，而图
17(b)中2的瓣膜与房室间隔区域清晰；图17(b)中1
的心室心房区域亮度适中，图17(b)中2的心室心房
区域较亮，而图17(b)中3、4的心室心房区域较暗。
表9图17(C)的评测结果
Table 9
The assessment results of Fig．17(c)
从表9和图17(c)可以看出，图17(c)中1、2、4
的面积之比适中，而图17(c)中3的面积之比较小；
图17(c)中1—4的瓣膜与房室间隔清晰；图17(e)中
1—3的心室心房亮度适中，而图17(c)4的心室心房
亮度较暗。
表10图17(d)的评测结果
Table 10
The assessment results of Fig．17(d)
从表10和图17(d)可以看出，图17(d)中1的瓣
膜与房室间隔区域清晰，且心室心房区域亮度适中，
但瓣膜与房室间隔区域较细，导致面积之比较
小；图17(d)中2的瓣膜与房室间隔区域欠清晰，但
面积之比适中，且心室心房区域较暗；图17(d)中3的
面积之比适中，瓣膜与房室间隔区域清晰，虽然心室
心房区域整体亮度适中，但局部亮度较大；图17(d)
中4的面积之比较小，瓣膜与房室间隔欠清晰，但
心室心房区域亮度适中。可以看出，当面积之比较
小，且其他一项或两项评测指标数值较大时，容易
造成误分类。
4结
论
本文针对基于深度学习的图像分类网络无法判
断胎儿四腔心超声切面图像中各解剖部件的位置关
系，而目标检测模型又元法准确反映其解剖部件的
可见程度，从而导致评测结果不可靠的问题，提出了
一种结合目标检测与两级分割的胎儿四腔心超声切
面图像质量评测方法。该方法将质量评测任务主要
分解成4个阶段。具体而言，1)利用YOLOv5x模型
考察四腔心区域与胸腔区域的位置关系，当检测到
四腔心区域在胸腔区域内时，将其视为感兴趣区域
提取出来。结果表明所训练的YOL0v5x模型在检
测四腔心区域和胸腔区域上具有良好的检测性能。
2)利用U2-Net实现四腔心内部区域的分割，即将心
室心房区域和瓣膜连同房室间隔区域共同视为前景
目标分割出来。结果表明所训练的ULNet模型在分
割四腔心内部区域上具有较好的分割性能。3)实现
四腔心内部区域解剖部件的分割与提取，即采用形
态学算子、直方图修正与OTSU结合的方法分割出
瓣膜连同房室间隔区域，再利用减法操作得到心室
心房区域的分割图，然后通过掩膜操作分别提取瓣
膜连同房室间隔区域以及心室心房区域。相比于深
度学习的分割方法，这种分割方法不仅在标注数据
上节省了大量的时间和精力，而且还节省了大量在
模型训练和推理阶段的开销，且更具有可解释性。
4)根据预先设定的评测规则输出相应的质量评测报
告。结果表明本文提出的质量评测方法具有较好的
实际应用价值。
虽然本文将定位与分割方法结合起来能够较好
地对胎儿四腔心超声切面图像进行质量评测，但整
个方案还存在很大的深入研究空问，首先本文所构
建的胎儿四腔心区域检测与四腔心内部区域分割数
据集都来自于同一种超声设备，其多样性不足，后续
可寻找更多合作单位获取其他类型的超声设备数据
进行实验。另外，在目标检测及四腔心区域分割时，
没能充分利用网络提取到的特征，从而输出更多的
辅助性信息，如心尖朝向，左右心室心房的划分等，
这些信息在临床诊断中也具有重要的参考价值，后
续将进一步深入开展这方面的工作。
万方数据



### 图片

![基于两级分割的胎儿四腔心超声切面质量评测_page13_img1.png](images/基于两级分割的胎儿四腔心超声切面质量评测_page13_img1.png)

## Page 14

徐光柱，钱奕凡，王阳．刘蓉．周军，雷帮军
第28卷／第8期／2023年8月
基于两级分割的胎儿四腔心超声切面质量评测
参考文献(References)
Abdi A H，Luong C，Tsang T，Allan G，Nouranian S，Jue J，Hawley
D，Fleming S，Gin K，Swift J，Rohling R and Abolmaesumi
P．
2017．Automatic quality assessment of echocardiograms using con—
volutional neural networks：feasibility on
the apical four-chamber
view．IEEE Transactions
on Medical Imaslng，36(6)：1221—1230
[DOI：10．1109／TMl．2017．2690836]
Baumgartner C F，Kamnitsas K，Matthew J，Fletcher T P，Smith S，
Koch L M。Kainz B and Rueckert
D．2017．Sononet：real．time
detection and localisation
of fetal standard
scan planes in freehand
dtrasound．IEEETransactions onMedicalImaging。36(11)：2204-
2215[DOI：10．1109／TMI．2017．2712367]
Boehkovskiy A．Wang C Y and Line H Y M．2020．YOLOv4：optimal
speed and accuracyofobject detection[EB／OL]．[2022-03．28]．
https：／／arxiv．org／pd．f12004．10934．pdf
ChenK，Wang JQ，Pang JM，CaoYH，XiongY，LiXX，Sun SY，
Feng W S，Liu Z W，Xu J R，Zhang Z，Cheng D Z，Zhu C C．
Cheng T H，Zhao Q J，Li B Y，Lu X，Zhu R，Wu Y，Dai
J
F，
Wang J
D，Shi J P，Ouyang W L，Loy C C and Lin D H．2019．
MMDetection：open MMLab detection toolbox and benchmark[EB／
OL]．[2022-03—28]．https：／／arxiv．org，pdffl906．07155．pdf
Chen Q，Wang Y M，Yang T，Zhang X Y，Chang
J and Sun J．2021．
You only
look
one—level feature／／Proeeedings of 2021
IEEE／CVF
Conference on Computer Vision and Pattern Recognition(CVPR)．
Nashville，USA：IEEE．[DOI：10．1109，cVPR46437．2021．01284]
Del Bianco A，Russo S，Lacerenza N，Rinaldi M，Rinaldi G．Nappi L
and Greco P．2006．Four chamber view plus
three—vessel and
tra—
chea view for a complete evaluation of the fetal heart during the sec-
end trimester．Journal of Perinatal Medicine，34(4)：309．312
【DOI：10．1515／JPM．2006．059]
Dong J B，Liu S F，LineYM，WenHX，Lei BY，Li S L andWangT
F．2020．A
generic quality control framework
for fetal ultrasound
cardiac
four-chamber planes．mEE Journal
of
Biomedical
and
Health Informatics，24(4)：931-942[DOI：10．1 109／JBHI．2019．
2948316]
Dudley N J and Chapman E．2002，The importance
of quality manage．
ment
in fetal measurement．Ultrasound in Obstetrics and Gynecol-
ogy，19(2)：190-196[DOI：10．10460．0960．7692．2001．00549．x]
GeQ Q，ZhangZ J，Yuan L，LiXM and Sun JM．2021．Safety helmet
wearing detection method
of
fusing
environmental
features and
improved YOLOv4．Journal
of
Image and Graphics，26(12)：
2904-2917(葛青青，张智杰，袁珑，李秀梅，孙军梅．2021．融
合环境特征与改进YOLOv4的安全帽佩戴检测．中国图象图形
学报，26(12)：2904-2917)[DOI：10．1 18341jig．200606]
Ge Z，“u S T，Wang F，Li Z M and Sun J．2021．YOLOX：exceeding
YOLO series in 2021[EB／OL]．[2022—03—28]．
https：／／arxiv．org／pd92107．08430．pdf
Jeanty P，Chaoui R，Tihonenko I and Grochal F．2007．A review of find—
ings in fetal cardiac section drawings：part 1：the 4-chamber view．
Journal ofUltrasound
in Medicine。26(11)：1601—1610[DOI：10．
7863／jum．2007．26．1 1．1601 J
Lange L W，Sahn D J，Allen H D，Goldberg S J，Anderson C and Giles
H．1980．Qualitative
real-time
cross-sectional echocardiographic
imaging of the human fetus during the second half of pregnancy．Cir-
culation，62(4)：799．806[DOI：10．116I／01．CIR．62．4．799]
Lin Z H，Le M H。Ni D，Cben S P，Li S L，Wang T F and Lei B Y．
2018．Quality assessment
of fetal head ultrasound images based on
Faster R··CNN／／Proeeedings of International Workshops
on
Simula··
tion．Image Processing．and Ultrasound Systems for Assisted Diag-
nosis and Navigation．Granada，Spain：Springer，1 1042：38-46
【DOI：10．1007／978-3-030—01045～一5J
Otsu N．1979．A threshold selection method from gray—level histograms．
IEEE Transactions
on Systems，Man．and Cybernetics．9(1)：
62．66[DOI：10．1 109／TSMC．1979．4310076]
Qin X B，Zhang Z C，Huang C Y，Dehghan M，Zaiane 0 R and Jager-
sand
M．2020．U2-Net：going deeper with
nested
u-structure for
salient
object
detection．Pattern
Recognition，106：#107404
[DOI：10．10166．patcog．2020．107404]
Rahmatullah B，Sarris I，Papageorghiou A and Noble J A．2011．Quality
control of fetal ultrasound images：detection of abdomen anatomical
landmarks using adaboost／／Proceedings of 201 1 IEEE International
Symposium on Biomedical Imaging：From Nano
to Macro．Chicago，
USA：IEEE：6-9【DOI：10．I 109／ISBI．201 1．5872342]
Redmon J，Divvala S。Girshiek R and Farhadi A．2016．You only look
once：unified，real-time
object
detection／／Proceedings
of
2016
IEEE
Conference
on
Computer
Vision
and Pattern
Recognition
(CVPR)．Las Vegas，USA：IEEE：#91[DOI：10．1109／CVPR．
2016．91]
Redmon
J and Farhadi A．2017．YOL09000：better，faster，stronger／／
Proceeding of 2017 IEEE Conference
on Computer Vision and Pat-
tern Recognition．Honolulu，USA：IEEE：6517-6525[DOI：10．
1 109／CVPR．2017．690J
Redmon J and Farhadi A．2018．YOLOv3：an incremental improvement
[EB／OL]．[2022-03-28]．https：／／arxiv．org／pd91804．02767．pdf
Ren SO，HeKM，GirshickR and Sun J．2017．FasterR-CNN：towards
real-time object
detection们【h
region
proposal
networks．IEEE
Transactions
on
Pattern
AnMysis
and
Machine
Intelligence，
39(6)：l 137．1 149[DOI：10．1109／TPAMI．2016．257703I]
Ronneberger O．Fischer P and Brox T．2015．U—Net：convolutionsl
net—
works for biomedical image segmentation／／Proceedings of the
18th
International
Conference
on
Medical
Image
Computing
and
Computer-Assisted
Intervention．Munich。Germany：Springer：
[DOI：10．1007／978—3-319-24574．4 28]
Salomon L J，Bernard
J P，Duyme M，Doris
B，Mas N and Ville
Y．
2006．Feasibility and
reproducibility of an
image-scoring method
万方数据



### 图片

![基于两级分割的胎儿四腔心超声切面质量评测_page14_img1.png](images/基于两级分割的胎儿四腔心超声切面质量评测_page14_img1.png)

## Page 15

2490
中国图象图形学报
JOURNAL OF IMAGE AND GRAPHICS
V01．28，NO．8，Aug．2023
for quality control of fetal biometry
in
the second trimester．Ultra．
sound
in Obstetrics and Gynecology，27(1)：34-40[DOI：10．
1002／uog．2665j
Salomon L J aud Ville Y．2005．Quality control of prenatal ultrasound．
The
Ultrasound
Review
of Obstetrics
and Gynecology，5(4)：
297—303[DOI：10．3109／14722240500415419]
Shelhamer E，Long J and Darrell T．2017．FuHy convolutional networks
for semantic segmentation．IEEE Transactions
on
Pattern Analysis
and
Machine InteHigenee，39(4)：640．651[DOI：10．1 109／
TPAMI．2016．2572683]
Uhralytics．2020 YOLOV5[EB／OL]．[2022—03—28 3．
https：／／github．eom／uhralyties／)rcloy5
VuUings R．2019．Fetal electrocardiography and deep learning for prena—
tal detection of congenital heart disease／／Proceedings of 2019 Com—
puting in Cardiology．Singapore，Singapore：IEEE：1-4[DOI：10．
22489／CinC．2019．072]
WangY，GeX K，MaH，Qi s L，Zhang G J andYaoY D．2021．Deep
]earning
in
medical ultrasound
image analysis：a
review．IEEE
Access，9：54310—54324 lDOI：10．1 109／ACCESS．2021．3071301]
Wu L Y，Cheng
J Z，Li S L，Lei B Y，Wang T F and Ni
D．2017．
FUIQA：fetal ultrasound image quality assessment with deep convo-
iutional
networks．IEEE Transactions
Oil
Cybernetics，47(5)：
1336—1349[DOI：10．1109／TCYB．2017．2671898]
WuYD，GongM，GuXY，ZhangH J andHeYH．2021．Advancesin
machine learning in the field of cardiac ultrasound．Journal of ClJni—
cal Uhrasound in Medicine，23(9)：692．694(武玉多，贡鸣，谷
孝艳，张宏家，何怡华．2021．机器学习在心脏超声领域中的研
究进展，临床超声医学杂志，23(9)：692—694)[DOI：10．16245／
j．cnki．issnl008-6978．2021．09．017]
Yagel S，Cohen S M and Achiron R．2001．Examination of the fetal heart
by five short—axis views：8 proposed screening method for compre—
hensive cardiac evaluation．Ultrasound
in Obstetrics
and Gyneeol—
ogy．17(5)：367．369[DOI：10．104@．1469—0705．2001．00414．X]
Zhang
B，Liu
H，Luo H and
Li K J．2021a．Automatic
quality
assessment
for 2D
fetal
sonographie
standard
plane based
on
multitask learning．Medicine，100(4)：#24427[DOI：10．1097／
MD．0000000000024427]
Zhang S Y，Wang Y F，Jiang J Y，Dong J X，Yi W W and Hou W
G．
2021b．CNN—based medical ultrasound image quality
assessment．
Complexity，2021：#9938367[DOh 10．1155／202119938367]
Zhou Z W，Siddiquee M M R，Tajbakhsh N and Liang J M．2018．
Unet++：a nested U—Net architecture for medical image segmenta-
tion／／Praeeedings of the 4th Intemational Workshop Deep Learning
in
Medical Image Analysis
and Muhimodal
I．earning for Clinical
Dceision Support．Granada，Spain：Springer．[DOI：10．1007／978—
3-030—00889—5j]
Zhu J W．2020．Unet—ZOO[EB／OL]．[2022—03—28]，
https：／／github．com／Andy—zhujunwen／UNET-ZOO
作者简介
徐光柱，男，教授，主要研究方向为计算机视觉、图像处理。
E—mail：xgz@ctgu．edu．CFI
雷帮军，通信作者，男，教授，主要研究方向为计算机视觉、机
器学习。E-mail：bangjun．1ei@ieee．org
钱奕凡，男，硕士研究生，主要研究方向为计算机视觉、图像
处理。E—mail：1 183 162729@qq．ecru
王阳，女，硕士研究生，主要研究方向为医学超声影像、超声
诊断。E—mail：479543042@qq．COrn
刘蓉，女，主任医师，主要研究方向为医学超声影像、超声诊
断。E．mail：stream0917@163．corn
周军，男，教授，主任医师，主要研究方向为医学超声影像、超
声诊断。E．mail：zjsts8@163．Corn
万方数据



### 图片

![基于两级分割的胎儿四腔心超声切面质量评测_page15_img1.png](images/基于两级分割的胎儿四腔心超声切面质量评测_page15_img1.png)
